{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“bert_text_classification.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donnychan1606/bert_IMDb/blob/master/%E2%80%9Cbert_text_classification_epoch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYoyLfLQI-t",
        "colab_type": "text"
      },
      "source": [
        "base code borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
        "\n",
        "Refactored by [Shuyi Wang](https://www.linkedin.com/in/shuyi-wang-b3955026/) and [Yan Sun](https://github.com/SunYanCN)\n",
        "\n",
        "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQHcJlAgHZ2o",
        "colab_type": "code",
        "outputId": "10444011-714b-4dfa-a339-af4375feec93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "!pip install bert-text"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-text in /usr/local/lib/python3.6/dist-packages (5.0.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-text) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (from bert-text) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bert-text) (4.28.1)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (from bert-text) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub->bert-text) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub->bert-text) (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2018.9)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub->bert-text) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (0.15.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu->bert-text) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu->bert-text) (3.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1RErtsuapWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "477402f4-2d05-44d1-eb8f-911b47d1b413"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP9EwULlbBgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7c0e690f-31cc-472d-f7cc-7859bd8f1fdb"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZFDseXWHiSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert_text import run_on_dfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0rXwQIYrjSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiOyfxH6H5ry",
        "colab_type": "code",
        "outputId": "444d4267-91a7-48b9-80f8-05858cdee9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-29 02:45:43--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12909082 (12M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-29 02:45:44 (106 MB/s) - ‘test.csv’ saved [12909082/12909082]\n",
            "\n",
            "--2019-05-29 02:45:45--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43221547 (41M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  41.22M   175MB/s    in 0.2s    \n",
            "\n",
            "2019-05-29 02:45:46 (175 MB/s) - ‘train.csv’ saved [43221547/43221547]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEGtiE42IDyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlzVWOZlskp",
        "colab_type": "code",
        "outputId": "edf1871b-caff-4e84-ee5f-f0a1989734a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "train.head"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                   review  label\n",
              "0      Story of a man who has unnatural feelings for ...      0\n",
              "1      Airport '77 starts as a brand new luxury 747 p...      0\n",
              "2      This film lacked something I couldn't put my f...      0\n",
              "3      Sorry everyone,,, I know this is supposed to b...      0\n",
              "4      When I was little my parents took me along to ...      0\n",
              "5      \"It appears that many critics find the idea of...      0\n",
              "6      The second attempt by a New York intellectual ...      0\n",
              "7      I don't know who to blame, the timid writers o...      0\n",
              "8      This film is mediocre at best. Angie Harmon is...      0\n",
              "9      The film is bad. There is no other way to say ...      0\n",
              "10     This film is one giant pant load. Paul Schrade...      0\n",
              "11     The plot for Descent, if it actually can be ca...      0\n",
              "12     Plot is not worth discussion even if it hints ...      0\n",
              "13     This film is about a male escort getting invol...      0\n",
              "14     This movie must be in line for the most boring...      0\n",
              "15     A worn-out plot of a man who takes the rap for...      0\n",
              "16     I saw this movie at a drive-in in 1959. Until ...      0\n",
              "17     Ghost of Dragstrip Hollow is a typical 1950's ...      0\n",
              "18     \"Ghost of Dragstrip Hollow\" was one of the man...      0\n",
              "19     \"Ghost of Dragstrip Hollow\" appears to take pl...      0\n",
              "20     The characters are unlikeable and the script i...      0\n",
              "21     Kareena Kapoor in a bikini hmmmmmmmm.<br /><br...      0\n",
              "22     I rented this on DVD and I kind of feel bad si...      0\n",
              "23     Vijay Krishna Acharya's 'Tashan' is a over-hyp...      0\n",
              "24     The worst movie I have seen since Tera Jadoo C...      0\n",
              "25     Summer season is here when the choices in the ...      0\n",
              "26     Shame on Yash Raj films and Aditya Chopra who ...      0\n",
              "27     First lesson that some film makers (particular...      0\n",
              "28     If this is a 2008 product from one of the bigg...      0\n",
              "29     I had some expectation for the movie, since it...      0\n",
              "...                                                  ...    ...\n",
              "32470  I was expecting \"Born to Kill\" to be an exciti...      0\n",
              "32471  Fellow Giallo-fanatics: beware and/or proceed ...      0\n",
              "32472  I'm almost embarrassed to admit to seeing CALI...      0\n",
              "32473  I rated this movie a 3 and that was generous. ...      0\n",
              "32474  \"Caligula\" shares many of the same attributes ...      0\n",
              "32475  Writer & director Robert Downey, Sr., a pionee...      0\n",
              "32476  Probably not the same version as most of the o...      0\n",
              "32477  Who really wants to see that? Disgusting viole...      0\n",
              "32478  As a semi-film buff, I had heard of this infam...      0\n",
              "32479  210 minute version (extremely hardcore, or so ...      0\n",
              "32480  Although its plot is taken from the history of...      0\n",
              "32481  I found the movie at my local video store and ...      0\n",
              "32482  As an ancient movie fan, I had heard much abou...      0\n",
              "32483  Incomprehensibly dreadful mishmash of the prob...      0\n",
              "32484  I'm currently slogging through Gibbon's 'Fall ...      0\n",
              "32485  It's a rare sensation to come across a film so...      0\n",
              "32486  Starting with a tearjerking poem and images of...      0\n",
              "32487  I saw this film at the tender age of 18 with a...      0\n",
              "32488  It's rare to see film that strikes out in ever...      0\n",
              "32489  Some describe CALIGULIA as \"the\" most controve...      0\n",
              "32490  As I read the script on-line, I thought \"Capot...      0\n",
              "32491  In this film, we're invited to observe the des...      0\n",
              "32492  many people said this was a great movie with H...      0\n",
              "32493  This is one dreary, inert, self-important bore...      0\n",
              "32494  Awful, awful, awful times a hundred still does...      0\n",
              "32495  I occasionally let my kids watch this garbage ...      0\n",
              "32496  When all we have anymore is pretty much realit...      0\n",
              "32497  The basic genre is a thriller intercut with an...      0\n",
              "32498  Four things intrigued me as to this film - fir...      0\n",
              "32499  David Bryce's comments nearby are exceptionall...      0\n",
              "\n",
              "[32500 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-kX0BXGlQ8-",
        "colab_type": "code",
        "outputId": "cded8008-eec2-4ff3-994c-b3900473e921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "test.head"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                  review  label\n",
              "0     I went and saw this movie last night after bei...      1\n",
              "1     Actor turned director Bill Paxton follows up h...      1\n",
              "2     As a recreational golfer with some knowledge o...      1\n",
              "3     I saw this film in a sneak preview, and it is ...      1\n",
              "4     Bill Paxton has taken the true story of the 19...      1\n",
              "5     I saw this film on September 1st, 2005 in Indi...      1\n",
              "6     Maybe I'm reading into this too much, but I wo...      1\n",
              "7     I felt this film did have many good qualities....      1\n",
              "8     This movie is amazing because the fact that th...      1\n",
              "9     \"Quitting\" may be as much about exiting a pre-...      1\n",
              "10    I loved this movie from beginning to end.I am ...      1\n",
              "11    I was fortunate to attend the London premier o...      1\n",
              "12    I first saw this movie on IFC. Which is a grea...      1\n",
              "13    I must say, every time I see this movie, I am ...      1\n",
              "14    My wife is a mental health therapist and we wa...      1\n",
              "15    I saw this film at the Rotterdam International...      1\n",
              "16    \"Night of the Hunted\" stars French porn star B...      1\n",
              "17    Even if you're a fan of Jean Rollin's idiosync...      1\n",
              "18    I was surprised how much I enjoyed this. Sure ...      1\n",
              "19    I went into \"Night of the Hunted\" not knowing ...      1\n",
              "20    I have certainly not seen all of Jean Rollin's...      1\n",
              "21    Since this cartoon was made in the old days, F...      1\n",
              "22    Despite the title and unlike some other storie...      1\n",
              "23    Felix in Hollywood is a great film. The versio...      1\n",
              "24    A gem of a cartoon from the silent era---it wa...      1\n",
              "25    This short is one of the best of all time and ...      1\n",
              "26    Felix is watching an actor rehearse his lines:...      1\n",
              "27    While I can't say whether or not Larry Hama ev...      1\n",
              "28    Errol Flynn's roguish charm really shines thro...      1\n",
              "29    Warner Brothers tampered considerably with Ame...      1\n",
              "...                                                 ...    ...\n",
              "9970  Well, I'm a huge fan and follower of Elizabeth...      0\n",
              "9971  This movie might be o.k. if not for all the la...      0\n",
              "9972  what happened to Mathew Modine's career??? i c...      0\n",
              "9973  Despite this being one of John Cusack and Demi...      0\n",
              "9974  Savage Steve Holland wrote and directed his se...      0\n",
              "9975  This is beyond stupid. <br /><br />Two high sc...      0\n",
              "9976  I hated the book. A guy meets a smart dog, get...      0\n",
              "9977  Wow! What a movie if you want to blow your bud...      0\n",
              "9978  okay, my question; who's the idiot that wrote ...      0\n",
              "9979  I couldn't agree more. The book is one of Dean...      0\n",
              "9980  Corey Haim plays a kid who teams up with a dog...      0\n",
              "9981  Corey Haim is never going to be known as one o...      0\n",
              "9982  Dean Koontz's book \"Watchers\" is one of the fi...      0\n",
              "9983  I still find it hard to believe that a fine - ...      0\n",
              "9984  This was a film based on the Novel written by ...      0\n",
              "9985  It is hard to believe that anyone could take s...      0\n",
              "9986  Every time I think about this film I feel phys...      0\n",
              "9987  Based on the excellent novel, Watchers by Dean...      0\n",
              "9988  Ugh. Pretty awful.<br /><br />Linnea Quigley g...      0\n",
              "9989  So many bad reviewers, it made me wonder, what...      0\n",
              "9990  No words can describe how awful this film is. ...      0\n",
              "9991  Oh If any day u wanna see a supernatural thril...      0\n",
              "9992  Friday the 13th meets the Matrix. As with all ...      0\n",
              "9993  I am ashamed to admit in public that I even he...      0\n",
              "9994  If you have seen this movie, then you will kno...      0\n",
              "9995  hi, This is the worst movie I have ever seen i...      0\n",
              "9996  An insane assault on viewers senses. This is a...      0\n",
              "9997  OK, I would give this a 1, but I'm gonna give ...      0\n",
              "9998  This movie made me laugh so much. It was a blo...      0\n",
              "9999  In Halloween, three friends seek an ancient ce...      0\n",
              "\n",
              "[10000 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6wlSR8NIKHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCoK42AGIXsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myparam = {\n",
        "    \"DATA_COLUMN\": \"review\",\n",
        "    \"LABEL_COLUMN\": \"label\",\n",
        "    \"LEARNING_RATE\": 2e-5,\n",
        "    \"NUM_TRAIN_EPOCHS\": 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUwqGJuIfgap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoOVNBr7IsjS",
        "colab_type": "code",
        "outputId": "6b834979-4cf1-4498-d3ef-837ac6ceab05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3301
        }
      },
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:50.397493 139706668738432 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.716197 139706668738432 run_classifier.py:774] Writing example 0 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.721979 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.726898 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the movie is more about pony than grey owl . it ' s also about aboriginal ##s , canada , the english , grey owl ' s aunt ##s and the north bay nu ##gg ##et . excellent story . < br / > < br / > this is an excellent movie , more like a book , that raises interesting questions about cultural identity and values . the key scene is grey owl admitting his imp ##ost ##ure to pony and her reaction . < br / > < br / > a few observations on the user ratings . note that the user ratings are bi - polar cluster ##ing at 5 and 7 ; it ' s not for everyone , but [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.730064 139706668738432 run_classifier.py:464] tokens: [CLS] the movie is more about pony than grey owl . it ' s also about aboriginal ##s , canada , the english , grey owl ' s aunt ##s and the north bay nu ##gg ##et . excellent story . < br / > < br / > this is an excellent movie , more like a book , that raises interesting questions about cultural identity and values . the key scene is grey owl admitting his imp ##ost ##ure to pony and her reaction . < br / > < br / > a few observations on the user ratings . note that the user ratings are bi - polar cluster ##ing at 5 and 7 ; it ' s not for everyone , but [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3185 2003 2062 2055 15606 2084 4462 13547 1012 2009 1005 1055 2036 2055 9757 2015 1010 2710 1010 1996 2394 1010 4462 13547 1005 1055 5916 2015 1998 1996 2167 3016 16371 13871 3388 1012 6581 2466 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2003 2019 6581 3185 1010 2062 2066 1037 2338 1010 2008 13275 5875 3980 2055 3451 4767 1998 5300 1012 1996 3145 3496 2003 4462 13547 17927 2010 17727 14122 5397 2000 15606 1998 2014 4668 1012 1026 7987 1013 1028 1026 7987 1013 1028 1037 2261 9420 2006 1996 5310 8599 1012 3602 2008 1996 5310 8599 2024 12170 1011 11508 9324 2075 2012 1019 1998 1021 1025 2009 1005 1055 2025 2005 3071 1010 2021 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.733588 139706668738432 run_classifier.py:465] input_ids: 101 1996 3185 2003 2062 2055 15606 2084 4462 13547 1012 2009 1005 1055 2036 2055 9757 2015 1010 2710 1010 1996 2394 1010 4462 13547 1005 1055 5916 2015 1998 1996 2167 3016 16371 13871 3388 1012 6581 2466 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2003 2019 6581 3185 1010 2062 2066 1037 2338 1010 2008 13275 5875 3980 2055 3451 4767 1998 5300 1012 1996 3145 3496 2003 4462 13547 17927 2010 17727 14122 5397 2000 15606 1998 2014 4668 1012 1026 7987 1013 1028 1026 7987 1013 1028 1037 2261 9420 2006 1996 5310 8599 1012 3602 2008 1996 5310 8599 2024 12170 1011 11508 9324 2075 2012 1019 1998 1021 1025 2009 1005 1055 2025 2005 3071 1010 2021 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.735954 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.739673 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.743018 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.765808 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.768299 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] john van dr ##ute ##n ' s \" bell , book and candle \" is a delightful and unexpected fantasy about a coven of modern - day witches living in new york city ; it was obviously an attractive movie property . it had a stellar part for gillian ho ##lr ##oy ##d , for her er ##st ##while book publisher enforced - sweetheart , shepherd henderson and her mad ##cap family and circle , including she ##p ' s bewildered fia ##nca ##a ##© ##e , the hate ##ful mer ##le kit ##tre ##dge , against whose chances with she ##p gillian begins her magical spell - casting . it even had p ##ye ##wa ##cke ##t , a siam ##ese cat - familiar with [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.770380 139706668738432 run_classifier.py:464] tokens: [CLS] john van dr ##ute ##n ' s \" bell , book and candle \" is a delightful and unexpected fantasy about a coven of modern - day witches living in new york city ; it was obviously an attractive movie property . it had a stellar part for gillian ho ##lr ##oy ##d , for her er ##st ##while book publisher enforced - sweetheart , shepherd henderson and her mad ##cap family and circle , including she ##p ' s bewildered fia ##nca ##a ##© ##e , the hate ##ful mer ##le kit ##tre ##dge , against whose chances with she ##p gillian begins her magical spell - casting . it even had p ##ye ##wa ##cke ##t , a siam ##ese cat - familiar with [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2198 3158 2852 10421 2078 1005 1055 1000 4330 1010 2338 1998 13541 1000 2003 1037 26380 1998 9223 5913 2055 1037 25248 1997 2715 1011 2154 12566 2542 1999 2047 2259 2103 1025 2009 2001 5525 2019 8702 3185 3200 1012 2009 2018 1037 17227 2112 2005 22358 7570 20974 6977 2094 1010 2005 2014 9413 3367 19927 2338 6674 16348 1011 12074 1010 11133 9481 1998 2014 5506 17695 2155 1998 4418 1010 2164 2016 2361 1005 1055 24683 19807 20909 2050 29652 2063 1010 1996 5223 3993 21442 2571 8934 7913 11818 1010 2114 3005 9592 2007 2016 2361 22358 4269 2014 8687 6297 1011 9179 1012 2009 2130 2018 1052 6672 4213 19869 2102 1010 1037 25583 6810 4937 1011 5220 2007 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.772831 139706668738432 run_classifier.py:465] input_ids: 101 2198 3158 2852 10421 2078 1005 1055 1000 4330 1010 2338 1998 13541 1000 2003 1037 26380 1998 9223 5913 2055 1037 25248 1997 2715 1011 2154 12566 2542 1999 2047 2259 2103 1025 2009 2001 5525 2019 8702 3185 3200 1012 2009 2018 1037 17227 2112 2005 22358 7570 20974 6977 2094 1010 2005 2014 9413 3367 19927 2338 6674 16348 1011 12074 1010 11133 9481 1998 2014 5506 17695 2155 1998 4418 1010 2164 2016 2361 1005 1055 24683 19807 20909 2050 29652 2063 1010 1996 5223 3993 21442 2571 8934 7913 11818 1010 2114 3005 9592 2007 2016 2361 22358 4269 2014 8687 6297 1011 9179 1012 2009 2130 2018 1052 6672 4213 19869 2102 1010 1037 25583 6810 4937 1011 5220 2007 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.775167 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.777440 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.779599 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.785907 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.788470 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] drew barry ##more was excellent in this film . this role is the type of role you don ' t normally see drew play . her typical role is as a woman looking for love . the storyline is also great . < br / > < br / > when holly is implicated in her mother ' s murder she moves to l . a . she moves in with a guy who becomes her lover . but her brother who is in a mental prison hospital for what they believe is murder is almost killed she is wrong ##fully accused . it is then revealed to her lover that she has multiple personality disorder . after that another woman becomes paranoid when she ' [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.790555 139706668738432 run_classifier.py:464] tokens: [CLS] drew barry ##more was excellent in this film . this role is the type of role you don ' t normally see drew play . her typical role is as a woman looking for love . the storyline is also great . < br / > < br / > when holly is implicated in her mother ' s murder she moves to l . a . she moves in with a guy who becomes her lover . but her brother who is in a mental prison hospital for what they believe is murder is almost killed she is wrong ##fully accused . it is then revealed to her lover that she has multiple personality disorder . after that another woman becomes paranoid when she ' [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3881 6287 5974 2001 6581 1999 2023 2143 1012 2023 2535 2003 1996 2828 1997 2535 2017 2123 1005 1056 5373 2156 3881 2377 1012 2014 5171 2535 2003 2004 1037 2450 2559 2005 2293 1012 1996 9994 2003 2036 2307 1012 1026 7987 1013 1028 1026 7987 1013 1028 2043 9079 2003 20467 1999 2014 2388 1005 1055 4028 2016 5829 2000 1048 1012 1037 1012 2016 5829 1999 2007 1037 3124 2040 4150 2014 7089 1012 2021 2014 2567 2040 2003 1999 1037 5177 3827 2902 2005 2054 2027 2903 2003 4028 2003 2471 2730 2016 2003 3308 7699 5496 1012 2009 2003 2059 3936 2000 2014 7089 2008 2016 2038 3674 6180 8761 1012 2044 2008 2178 2450 4150 19810 2043 2016 1005 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.792465 139706668738432 run_classifier.py:465] input_ids: 101 3881 6287 5974 2001 6581 1999 2023 2143 1012 2023 2535 2003 1996 2828 1997 2535 2017 2123 1005 1056 5373 2156 3881 2377 1012 2014 5171 2535 2003 2004 1037 2450 2559 2005 2293 1012 1996 9994 2003 2036 2307 1012 1026 7987 1013 1028 1026 7987 1013 1028 2043 9079 2003 20467 1999 2014 2388 1005 1055 4028 2016 5829 2000 1048 1012 1037 1012 2016 5829 1999 2007 1037 3124 2040 4150 2014 7089 1012 2021 2014 2567 2040 2003 1999 1037 5177 3827 2902 2005 2054 2027 2903 2003 4028 2003 2471 2730 2016 2003 3308 7699 5496 1012 2009 2003 2059 3936 2000 2014 7089 2008 2016 2038 3674 6180 8761 1012 2044 2008 2178 2450 4150 19810 2043 2016 1005 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.794617 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.800381 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.802196 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.813105 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.815471 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] when the opening shot is u . s . marines seriously di ##sr ##es ##pe ##cting the u . s . flag , a movie has a tough road ahead , but unfortunately it was downhill from there . there is a military adviser credited , who is also apparently a retired u . s . marine , making it even more ba ##ff ##ling that this incredible breach of protocol , and law , went unnoticed . even more ba ##ff ##ling is the way they simply gloss ##ed over how a marine is reported kia , then buried , in very short order , without the slightest explanation of how they identified the body , or if there even was a body . the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.817255 139706668738432 run_classifier.py:464] tokens: [CLS] when the opening shot is u . s . marines seriously di ##sr ##es ##pe ##cting the u . s . flag , a movie has a tough road ahead , but unfortunately it was downhill from there . there is a military adviser credited , who is also apparently a retired u . s . marine , making it even more ba ##ff ##ling that this incredible breach of protocol , and law , went unnoticed . even more ba ##ff ##ling is the way they simply gloss ##ed over how a marine is reported kia , then buried , in very short order , without the slightest explanation of how they identified the body , or if there even was a body . the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2043 1996 3098 2915 2003 1057 1012 1055 1012 9622 5667 4487 21338 2229 5051 11873 1996 1057 1012 1055 1012 5210 1010 1037 3185 2038 1037 7823 2346 3805 1010 2021 6854 2009 2001 19448 2013 2045 1012 2045 2003 1037 2510 11747 5827 1010 2040 2003 2036 4593 1037 3394 1057 1012 1055 1012 3884 1010 2437 2009 2130 2062 8670 4246 2989 2008 2023 9788 12510 1997 8778 1010 1998 2375 1010 2253 22719 1012 2130 2062 8670 4246 2989 2003 1996 2126 2027 3432 27068 2098 2058 2129 1037 3884 2003 2988 27005 1010 2059 3950 1010 1999 2200 2460 2344 1010 2302 1996 15989 7526 1997 2129 2027 4453 1996 2303 1010 2030 2065 2045 2130 2001 1037 2303 1012 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.819508 139706668738432 run_classifier.py:465] input_ids: 101 2043 1996 3098 2915 2003 1057 1012 1055 1012 9622 5667 4487 21338 2229 5051 11873 1996 1057 1012 1055 1012 5210 1010 1037 3185 2038 1037 7823 2346 3805 1010 2021 6854 2009 2001 19448 2013 2045 1012 2045 2003 1037 2510 11747 5827 1010 2040 2003 2036 4593 1037 3394 1057 1012 1055 1012 3884 1010 2437 2009 2130 2062 8670 4246 2989 2008 2023 9788 12510 1997 8778 1010 1998 2375 1010 2253 22719 1012 2130 2062 8670 4246 2989 2003 1996 2126 2027 3432 27068 2098 2058 2129 1037 3884 2003 2988 27005 1010 2059 3950 1010 1999 2200 2460 2344 1010 2302 1996 15989 7526 1997 2129 2027 4453 1996 2303 1010 2030 2065 2045 2130 2001 1037 2303 1012 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.821648 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.823386 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.827928 139706668738432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.848404 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.851015 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] some movies are just a ? un ##lu ##cky . these are the films that obviously thrive ##d on a lot of goodwill and a handful of potentially great ideas , but simply didn ' t have the budget ##ary means and / or professional cast and crew members at their disposal to make it happen . \" the strange ##ness \" definitely belongs in this category . you really want to like it , but even the most tolerant and und ##eman ##ding 80 ' s horror fan ##atics will have to admit the film barely reaches the level of med ##io ##cr ##ity due to its atmosphere of cheap ##ness , clumsy stop - motion effects and imp ##ene ##tra ##bly dark cinematography . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.853266 139706668738432 run_classifier.py:464] tokens: [CLS] some movies are just a ? un ##lu ##cky . these are the films that obviously thrive ##d on a lot of goodwill and a handful of potentially great ideas , but simply didn ' t have the budget ##ary means and / or professional cast and crew members at their disposal to make it happen . \" the strange ##ness \" definitely belongs in this category . you really want to like it , but even the most tolerant and und ##eman ##ding 80 ' s horror fan ##atics will have to admit the film barely reaches the level of med ##io ##cr ##ity due to its atmosphere of cheap ##ness , clumsy stop - motion effects and imp ##ene ##tra ##bly dark cinematography . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2070 5691 2024 2074 1037 1029 4895 7630 17413 1012 2122 2024 1996 3152 2008 5525 25220 2094 2006 1037 2843 1997 22875 1998 1037 9210 1997 9280 2307 4784 1010 2021 3432 2134 1005 1056 2031 1996 5166 5649 2965 1998 1013 2030 2658 3459 1998 3626 2372 2012 2037 13148 2000 2191 2009 4148 1012 1000 1996 4326 2791 1000 5791 7460 1999 2023 4696 1012 2017 2428 2215 2000 2066 2009 1010 2021 2130 1996 2087 23691 1998 6151 16704 4667 3770 1005 1055 5469 5470 17592 2097 2031 2000 6449 1996 2143 4510 6561 1996 2504 1997 19960 3695 26775 3012 2349 2000 2049 7224 1997 10036 2791 1010 22902 2644 1011 4367 3896 1998 17727 8625 6494 6321 2601 16434 1012 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.855638 139706668738432 run_classifier.py:465] input_ids: 101 2070 5691 2024 2074 1037 1029 4895 7630 17413 1012 2122 2024 1996 3152 2008 5525 25220 2094 2006 1037 2843 1997 22875 1998 1037 9210 1997 9280 2307 4784 1010 2021 3432 2134 1005 1056 2031 1996 5166 5649 2965 1998 1013 2030 2658 3459 1998 3626 2372 2012 2037 13148 2000 2191 2009 4148 1012 1000 1996 4326 2791 1000 5791 7460 1999 2023 4696 1012 2017 2428 2215 2000 2066 2009 1010 2021 2130 1996 2087 23691 1998 6151 16704 4667 3770 1005 1055 5469 5470 17592 2097 2031 2000 6449 1996 2143 4510 6561 1996 2504 1997 19960 3695 26775 3012 2349 2000 2049 7224 1997 10036 2791 1010 22902 2644 1011 4367 3896 1998 17727 8625 6494 6321 2601 16434 1012 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.858016 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.860522 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:16:51.862561 139706668738432 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:17:40.778466 139706668738432 run_classifier.py:774] Writing example 10000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:18:30.594992 139706668738432 run_classifier.py:774] Writing example 20000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:20.433897 139706668738432 run_classifier.py:774] Writing example 30000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.852601 139706668738432 run_classifier.py:774] Writing example 0 of 10000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.858869 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.861484 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.865125 139706668738432 run_classifier.py:464] tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.868656 139706668738432 run_classifier.py:465] input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.871611 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.875317 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.878937 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.895184 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.897108 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.902404 139706668738432 run_classifier.py:464] tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.906903 139706668738432 run_classifier.py:465] input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.909662 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.911994 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.915465 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.928096 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.930375 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.933352 139706668738432 run_classifier.py:464] tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.935613 139706668738432 run_classifier.py:465] input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.938750 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.941461 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.944330 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.951929 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.954327 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.956431 139706668738432 run_classifier.py:464] tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.959817 139706668738432 run_classifier.py:465] input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.962013 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.965045 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.967350 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.977473 139706668738432 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.980326 139706668738432 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.982528 139706668738432 run_classifier.py:464] tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.984704 139706668738432 run_classifier.py:465] input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.986898 139706668738432 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.989677 139706668738432 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:19:32.991705 139706668738432 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0f764d4d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:21.288055 139706668738432 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0f764d4d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:21.327537 139706668738432 estimator.py:351] Skipping training since max_steps has already saved.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:27.401529 139706668738432 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:31.367810 139706668738432 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:41.411683 139706668738432 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-29T07:20:41Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:41.437320 139706668738432 evaluation.py:257] Starting evaluation at 2019-05-29T07:20:41Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:42.991401 139706668738432 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-6093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:43.003617 139706668738432 saver.py:1270] Restoring parameters from output/model.ckpt-6093\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:45.697501 139706668738432 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:20:46.014902 139706668738432 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-29-07:22:13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:22:13.632393 139706668738432 evaluation.py:277] Finished evaluation at 2019-05-29-07:22:13\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 6093: auc = 0.118000016, eval_accuracy = 0.118, f1_score = 0.6666666, false_negatives = 4625.0, false_positives = 4195.0, global_step = 6093, loss = 7.4236984, precision = 0.082056895, recall = 0.075, true_negatives = 805.0, true_positives = 375.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:22:13.634678 139706668738432 estimator.py:1979] Saving dict for global step 6093: auc = 0.118000016, eval_accuracy = 0.118, f1_score = 0.6666666, false_negatives = 4625.0, false_positives = 4195.0, global_step = 6093, loss = 7.4236984, precision = 0.082056895, recall = 0.075, true_negatives = 805.0, true_positives = 375.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6093: output/model.ckpt-6093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 07:22:13.641104 139706668738432 estimator.py:2039] Saving 'checkpoint_path' summary for global step 6093: output/model.ckpt-6093\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaZMjQ0cIw9y",
        "colab_type": "code",
        "outputId": "a965198b-34c3-4071-8ee4-97bc2ff66df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.118000016,\n",
              " 'eval_accuracy': 0.118,\n",
              " 'f1_score': 0.6666666,\n",
              " 'false_negatives': 4625.0,\n",
              " 'false_positives': 4195.0,\n",
              " 'global_step': 6093,\n",
              " 'loss': 7.4236984,\n",
              " 'precision': 0.082056895,\n",
              " 'recall': 0.075,\n",
              " 'true_negatives': 805.0,\n",
              " 'true_positives': 375.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}