{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-text-binary-classification-with-bert-Donny.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donnychan1606/bert_IMDb/blob/master/demo_text_binary_classification_with_bert_Donny_size500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbAMqZ6IZuw",
        "colab_type": "text"
      },
      "source": [
        "base code borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
        "\n",
        "Refactored by [Shuyi Wang](https://www.linkedin.com/in/shuyi-wang-b3955026/)\n",
        "\n",
        "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "trusted": true,
        "outputId": "4726c150-20c2-410b-d8ed-3fbe42035d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZM71PjIOF_I",
        "colab": {}
      },
      "source": [
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCYOL8HbIZu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(bert_model_hub)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      bert_model_hub,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "      bert_model_hub = bert_model_hub,\n",
        "      num_labels=len(label_list),\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, \n",
        "               MAX_SEQ_LENGTH = 128,\n",
        "              BATCH_SIZE = 32,\n",
        "              LEARNING_RATE = 2e-5,\n",
        "              NUM_TRAIN_EPOCHS = 3.0,\n",
        "              WARMUP_PROPORTION = 0.1,\n",
        "              SAVE_SUMMARY_STEPS = 100,\n",
        "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
        "              bert_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"):\n",
        "\n",
        "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
        "    \n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "                                  bert_model_hub, \n",
        "                                  OUTPUT_DIR, \n",
        "                                  SAVE_SUMMARY_STEPS, \n",
        "                                  SAVE_CHECKPOINTS_STEPS, \n",
        "                                  label_list, \n",
        "                                  LEARNING_RATE, \n",
        "                                  num_train_steps, \n",
        "                                  num_warmup_steps, \n",
        "                                  BATCH_SIZE)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    return result_dict, estimator\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wpUHTA8LIZu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qmP8MBvjIZvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = 'output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV3ExI2JJMhd",
        "colab_type": "text"
      },
      "source": [
        "----- you just need to focus from here ------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUjVoFtJVEO",
        "colab_type": "text"
      },
      "source": [
        "## Get your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ6CestJXZK",
        "colab_type": "code",
        "outputId": "ecea4bb2-c782-458d-96ec-c432dba959cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-30 04:09:14--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12909082 (12M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-30 04:09:15 (98.3 MB/s) - ‘test.csv’ saved [12909082/12909082]\n",
            "\n",
            "--2019-05-30 04:09:16--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43221547 (41M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  41.22M   177MB/s    in 0.2s    \n",
            "\n",
            "2019-05-30 04:09:17 (177 MB/s) - ‘train.csv’ saved [43221547/43221547]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFBwDlmnIZvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tju0c4dqIZvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8i4a5xUFfe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9BAxyKhKirc",
        "colab_type": "code",
        "outputId": "6c6af996-09d3-416c-8e30-037374a2361a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21551</th>\n",
              "      <td>This is a tongue in cheek movie from the very ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26758</th>\n",
              "      <td>Actually, I am not narrating the main plot in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12194</th>\n",
              "      <td>This a fascinatingly awful movie. It make so l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21976</th>\n",
              "      <td>One of the best if not the best rock'n'roll mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>This sword-&amp;-sorcery story of an appallingly b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "21551  This is a tongue in cheek movie from the very ...      1\n",
              "26758  Actually, I am not narrating the main plot in ...      0\n",
              "12194  This a fascinatingly awful movie. It make so l...      0\n",
              "21976  One of the best if not the best rock'n'roll mo...      1\n",
              "2756   This sword-&-sorcery story of an appallingly b...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDh-VkaxIcJq",
        "colab_type": "code",
        "outputId": "d5f9238b-4fe0-4eb6-b65c-10651038e38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape\n",
        "#test.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUuX8u8Itdc",
        "colab_type": "code",
        "outputId": "bd47b61f-5694-4c2f-aa9f-831207059620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM8M7k0gKk5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myparam = {\n",
        "        \"DATA_COLUMN\": \"review\",\n",
        "        \"LABEL_COLUMN\": \"label\",\n",
        "        \"LEARNING_RATE\": 2e-5,\n",
        "        \"NUM_TRAIN_EPOCHS\":3\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg2apeXpMqG-",
        "outputId": "cf009e1b-cc3b-456b-d897-5af9eb00bc1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:05.770035 140467944662912 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.303816 140467944662912 run_classifier.py:774] Writing example 0 of 500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.316007 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.319368 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is a tongue in cheek movie from the very outset with a voice - over that poke ##s fun at everything french and then produces a rather na ##if but very brave hero in fan ##fan la tu ##lip ##e . portrayed by the splendid gerard philippe , the dash ##ing young man believes utterly in the fate cu ##rva ##ce ##ous lo ##llo ##bri ##gi ##da fore ##tell ##s - notably that he will marry king louis xv ' s daughter ! problem is , la lo ##llo soon find outs she too is in love with fan ##fan . . . < br / > < br / > propelled by good sword fights , ca ##val ##cade ##s , and other spirited [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.324284 140467944662912 run_classifier.py:464] tokens: [CLS] this is a tongue in cheek movie from the very outset with a voice - over that poke ##s fun at everything french and then produces a rather na ##if but very brave hero in fan ##fan la tu ##lip ##e . portrayed by the splendid gerard philippe , the dash ##ing young man believes utterly in the fate cu ##rva ##ce ##ous lo ##llo ##bri ##gi ##da fore ##tell ##s - notably that he will marry king louis xv ' s daughter ! problem is , la lo ##llo soon find outs she too is in love with fan ##fan . . . < br / > < br / > propelled by good sword fights , ca ##val ##cade ##s , and other spirited [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1037 4416 1999 5048 3185 2013 1996 2200 26674 2007 1037 2376 1011 2058 2008 26202 2015 4569 2012 2673 2413 1998 2059 7137 1037 2738 6583 10128 2021 2200 9191 5394 1999 5470 15143 2474 10722 15000 2063 1012 6791 2011 1996 21459 11063 11169 1010 1996 11454 2075 2402 2158 7164 12580 1999 1996 6580 12731 19146 3401 3560 8840 7174 23736 5856 2850 18921 23567 2015 1011 5546 2008 2002 2097 5914 2332 3434 15566 1005 1055 2684 999 3291 2003 1010 2474 8840 7174 2574 2424 21100 2016 2205 2003 1999 2293 2007 5470 15143 1012 1012 1012 1026 7987 1013 1028 1026 7987 1013 1028 15801 2011 2204 4690 9590 1010 6187 10175 21869 2015 1010 1998 2060 24462 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.328779 140467944662912 run_classifier.py:465] input_ids: 101 2023 2003 1037 4416 1999 5048 3185 2013 1996 2200 26674 2007 1037 2376 1011 2058 2008 26202 2015 4569 2012 2673 2413 1998 2059 7137 1037 2738 6583 10128 2021 2200 9191 5394 1999 5470 15143 2474 10722 15000 2063 1012 6791 2011 1996 21459 11063 11169 1010 1996 11454 2075 2402 2158 7164 12580 1999 1996 6580 12731 19146 3401 3560 8840 7174 23736 5856 2850 18921 23567 2015 1011 5546 2008 2002 2097 5914 2332 3434 15566 1005 1055 2684 999 3291 2003 1010 2474 8840 7174 2574 2424 21100 2016 2205 2003 1999 2293 2007 5470 15143 1012 1012 1012 1026 7987 1013 1028 1026 7987 1013 1028 15801 2011 2204 4690 9590 1010 6187 10175 21869 2015 1010 1998 2060 24462 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.331852 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.337093 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.342688 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.351684 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.354326 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] actually , i am not na ##rra ##ting the main plot in this comment but with just 2 - 3 sentences i can make it a spoil ##er . ok here are these - < br / > < br / > speed is just a 85 % conversion of hollywood flick cellular into bollywood by using the software vikram b ##hat ##t . title has no match with the story , only it goes in the thriller direction . just that ! ! it doesn ' t deserve even a single star for its imitation , imperfect casting , poor standard and predictable story . undoubtedly now i can say that vi ##ram b ##hat ##t is slowly vanishing away from his director status as [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.357570 140467944662912 run_classifier.py:464] tokens: [CLS] actually , i am not na ##rra ##ting the main plot in this comment but with just 2 - 3 sentences i can make it a spoil ##er . ok here are these - < br / > < br / > speed is just a 85 % conversion of hollywood flick cellular into bollywood by using the software vikram b ##hat ##t . title has no match with the story , only it goes in the thriller direction . just that ! ! it doesn ' t deserve even a single star for its imitation , imperfect casting , poor standard and predictable story . undoubtedly now i can say that vi ##ram b ##hat ##t is slowly vanishing away from his director status as [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2941 1010 1045 2572 2025 6583 11335 3436 1996 2364 5436 1999 2023 7615 2021 2007 2074 1016 1011 1017 11746 1045 2064 2191 2009 1037 27594 2121 1012 7929 2182 2024 2122 1011 1026 7987 1013 1028 1026 7987 1013 1028 3177 2003 2074 1037 5594 1003 7584 1997 5365 17312 12562 2046 16046 2011 2478 1996 4007 29063 1038 12707 2102 1012 2516 2038 2053 2674 2007 1996 2466 1010 2069 2009 3632 1999 1996 10874 3257 1012 2074 2008 999 999 2009 2987 1005 1056 10107 2130 1037 2309 2732 2005 2049 20017 1010 29238 9179 1010 3532 3115 1998 21425 2466 1012 17319 2085 1045 2064 2360 2008 6819 6444 1038 12707 2102 2003 3254 24866 2185 2013 2010 2472 3570 2004 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.360689 140467944662912 run_classifier.py:465] input_ids: 101 2941 1010 1045 2572 2025 6583 11335 3436 1996 2364 5436 1999 2023 7615 2021 2007 2074 1016 1011 1017 11746 1045 2064 2191 2009 1037 27594 2121 1012 7929 2182 2024 2122 1011 1026 7987 1013 1028 1026 7987 1013 1028 3177 2003 2074 1037 5594 1003 7584 1997 5365 17312 12562 2046 16046 2011 2478 1996 4007 29063 1038 12707 2102 1012 2516 2038 2053 2674 2007 1996 2466 1010 2069 2009 3632 1999 1996 10874 3257 1012 2074 2008 999 999 2009 2987 1005 1056 10107 2130 1037 2309 2732 2005 2049 20017 1010 29238 9179 1010 3532 3115 1998 21425 2466 1012 17319 2085 1045 2064 2360 2008 6819 6444 1038 12707 2102 2003 3254 24866 2185 2013 2010 2472 3570 2004 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.364157 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.366691 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.370053 140467944662912 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.376750 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.379726 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this a fascinating ##ly awful movie . it make so little sense that it starts to make a kind of weird internal logic of its own . well , it would if it didn ' t keep darting off up side - alley ##s until eventually fl ##ound ##ering under the weight of its own ind ##ec ##isi ##ven ##ess . the movie can ' t make up its mind whether it is a straight forward ' man turns into monster ' flick ( like all those 1950s ' the incredible insert verb ing man ' movies ) , or a g ##has ##tly big business conspiracy theory movie , or a mystical afterlife contact story , or . . . or what ? take your [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.382183 140467944662912 run_classifier.py:464] tokens: [CLS] this a fascinating ##ly awful movie . it make so little sense that it starts to make a kind of weird internal logic of its own . well , it would if it didn ' t keep darting off up side - alley ##s until eventually fl ##ound ##ering under the weight of its own ind ##ec ##isi ##ven ##ess . the movie can ' t make up its mind whether it is a straight forward ' man turns into monster ' flick ( like all those 1950s ' the incredible insert verb ing man ' movies ) , or a g ##has ##tly big business conspiracy theory movie , or a mystical afterlife contact story , or . . . or what ? take your [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 1037 17160 2135 9643 3185 1012 2009 2191 2061 2210 3168 2008 2009 4627 2000 2191 1037 2785 1997 6881 4722 7961 1997 2049 2219 1012 2092 1010 2009 2052 2065 2009 2134 1005 1056 2562 24567 2125 2039 2217 1011 8975 2015 2127 2776 13109 28819 7999 2104 1996 3635 1997 2049 2219 27427 8586 17417 8159 7971 1012 1996 3185 2064 1005 1056 2191 2039 2049 2568 3251 2009 2003 1037 3442 2830 1005 2158 4332 2046 6071 1005 17312 1006 2066 2035 2216 4856 1005 1996 9788 19274 12034 13749 2158 1005 5691 1007 1010 2030 1037 1043 14949 14626 2502 2449 9714 3399 3185 1010 2030 1037 17529 25115 3967 2466 1010 2030 1012 1012 1012 2030 2054 1029 2202 2115 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.384803 140467944662912 run_classifier.py:465] input_ids: 101 2023 1037 17160 2135 9643 3185 1012 2009 2191 2061 2210 3168 2008 2009 4627 2000 2191 1037 2785 1997 6881 4722 7961 1997 2049 2219 1012 2092 1010 2009 2052 2065 2009 2134 1005 1056 2562 24567 2125 2039 2217 1011 8975 2015 2127 2776 13109 28819 7999 2104 1996 3635 1997 2049 2219 27427 8586 17417 8159 7971 1012 1996 3185 2064 1005 1056 2191 2039 2049 2568 3251 2009 2003 1037 3442 2830 1005 2158 4332 2046 6071 1005 17312 1006 2066 2035 2216 4856 1005 1996 9788 19274 12034 13749 2158 1005 5691 1007 1010 2030 1037 1043 14949 14626 2502 2449 9714 3399 3185 1010 2030 1037 17529 25115 3967 2466 1010 2030 1012 1012 1012 2030 2054 1029 2202 2115 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.387219 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.389899 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.392527 140467944662912 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.400587 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.402673 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] one of the best if not the best rock ' n ' roll movies ever . and it ' s not just mind ##less fun . there really were a lot of clever jokes in it . of course i love the ramon ##es . but with all the \" anarchy \" and the \" i hate high school \" themes , the film doesn ' t at all take itself too seriously , which is what ' s great about it . < br / > < br / > i first saw the movie in the spring of 1980 , and i saw it again recently . since i went to high school in the late 1970 ' s , it made me kind [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.404743 140467944662912 run_classifier.py:464] tokens: [CLS] one of the best if not the best rock ' n ' roll movies ever . and it ' s not just mind ##less fun . there really were a lot of clever jokes in it . of course i love the ramon ##es . but with all the \" anarchy \" and the \" i hate high school \" themes , the film doesn ' t at all take itself too seriously , which is what ' s great about it . < br / > < br / > i first saw the movie in the spring of 1980 , and i saw it again recently . since i went to high school in the late 1970 ' s , it made me kind [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2028 1997 1996 2190 2065 2025 1996 2190 2600 1005 1050 1005 4897 5691 2412 1012 1998 2009 1005 1055 2025 2074 2568 3238 4569 1012 2045 2428 2020 1037 2843 1997 12266 13198 1999 2009 1012 1997 2607 1045 2293 1996 12716 2229 1012 2021 2007 2035 1996 1000 26395 1000 1998 1996 1000 1045 5223 2152 2082 1000 6991 1010 1996 2143 2987 1005 1056 2012 2035 2202 2993 2205 5667 1010 2029 2003 2054 1005 1055 2307 2055 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2034 2387 1996 3185 1999 1996 3500 1997 3150 1010 1998 1045 2387 2009 2153 3728 1012 2144 1045 2253 2000 2152 2082 1999 1996 2397 3359 1005 1055 1010 2009 2081 2033 2785 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.407038 140467944662912 run_classifier.py:465] input_ids: 101 2028 1997 1996 2190 2065 2025 1996 2190 2600 1005 1050 1005 4897 5691 2412 1012 1998 2009 1005 1055 2025 2074 2568 3238 4569 1012 2045 2428 2020 1037 2843 1997 12266 13198 1999 2009 1012 1997 2607 1045 2293 1996 12716 2229 1012 2021 2007 2035 1996 1000 26395 1000 1998 1996 1000 1045 5223 2152 2082 1000 6991 1010 1996 2143 2987 1005 1056 2012 2035 2202 2993 2205 5667 1010 2029 2003 2054 1005 1055 2307 2055 2009 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2034 2387 1996 3185 1999 1996 3500 1997 3150 1010 1998 1045 2387 2009 2153 3728 1012 2144 1045 2253 2000 2152 2082 1999 1996 2397 3359 1005 1055 1010 2009 2081 2033 2785 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.409088 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.411175 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.413233 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.422229 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.424412 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this sword - & - so ##rce ##ry story of an app ##all ##ingly brutal and call ##ous \" hero \" van ##qui ##shing an evil king is worthless in almost every detail . the acting is horrible from the leads to the supporting roles . the lee ##ring , g ##lo ##ating glee with which the director shows the hero sm ##earing blood around is absolutely disgusting ; nor is it red ##eem ##ed by any justice to his cause , since he is as bad as the people he ' s fighting . z - movie editing is abundant , including a scene where a character \" dies \" from a sword thrust that very obviously missed completely ! < br / > < [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.426689 140467944662912 run_classifier.py:464] tokens: [CLS] this sword - & - so ##rce ##ry story of an app ##all ##ingly brutal and call ##ous \" hero \" van ##qui ##shing an evil king is worthless in almost every detail . the acting is horrible from the leads to the supporting roles . the lee ##ring , g ##lo ##ating glee with which the director shows the hero sm ##earing blood around is absolutely disgusting ; nor is it red ##eem ##ed by any justice to his cause , since he is as bad as the people he ' s fighting . z - movie editing is abundant , including a scene where a character \" dies \" from a sword thrust that very obviously missed completely ! < br / > < [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 4690 1011 1004 1011 2061 19170 2854 2466 1997 2019 10439 8095 15787 12077 1998 2655 3560 1000 5394 1000 3158 15549 12227 2019 4763 2332 2003 22692 1999 2471 2296 6987 1012 1996 3772 2003 9202 2013 1996 5260 2000 1996 4637 4395 1012 1996 3389 4892 1010 1043 4135 5844 18874 2007 2029 1996 2472 3065 1996 5394 15488 27242 2668 2105 2003 7078 19424 1025 4496 2003 2009 2417 21564 2098 2011 2151 3425 2000 2010 3426 1010 2144 2002 2003 2004 2919 2004 1996 2111 2002 1005 1055 3554 1012 1062 1011 3185 9260 2003 12990 1010 2164 1037 3496 2073 1037 2839 1000 8289 1000 2013 1037 4690 7400 2008 2200 5525 4771 3294 999 1026 7987 1013 1028 1026 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.428703 140467944662912 run_classifier.py:465] input_ids: 101 2023 4690 1011 1004 1011 2061 19170 2854 2466 1997 2019 10439 8095 15787 12077 1998 2655 3560 1000 5394 1000 3158 15549 12227 2019 4763 2332 2003 22692 1999 2471 2296 6987 1012 1996 3772 2003 9202 2013 1996 5260 2000 1996 4637 4395 1012 1996 3389 4892 1010 1043 4135 5844 18874 2007 2029 1996 2472 3065 1996 5394 15488 27242 2668 2105 2003 7078 19424 1025 4496 2003 2009 2417 21564 2098 2011 2151 3425 2000 2010 3426 1010 2144 2002 2003 2004 2919 2004 1996 2111 2002 1005 1055 3554 1012 1062 1011 3185 9260 2003 12990 1010 2164 1037 3496 2073 1037 2839 1000 8289 1000 2013 1037 4690 7400 2008 2200 5525 4771 3294 999 1026 7987 1013 1028 1026 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.430777 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.432826 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:06.435029 140467944662912 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:08.975273 140467944662912 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:08.998991 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.000711 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] \" 2001 : a space odyssey \" is set in 2001 and the main character is hal . a computer . that ' s right , a computer who talks and thinks entirely on its own . this was made in 1968 and to think by 2001 it would be con ##ce ##iva ##ble that computers would talk is a joke . if this was in 306 ##4 , a talking computer that had emotions and made its own decisions would be considered just as mor ##onic as this . there is nothing in this film that provoke ##s any kind of emotion . it provoke ##s two reactions and one is called : sleep . it starts with nothing , but a pitch black shot [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.002276 140467944662912 run_classifier.py:464] tokens: [CLS] \" 2001 : a space odyssey \" is set in 2001 and the main character is hal . a computer . that ' s right , a computer who talks and thinks entirely on its own . this was made in 1968 and to think by 2001 it would be con ##ce ##iva ##ble that computers would talk is a joke . if this was in 306 ##4 , a talking computer that had emotions and made its own decisions would be considered just as mor ##onic as this . there is nothing in this film that provoke ##s any kind of emotion . it provoke ##s two reactions and one is called : sleep . it starts with nothing , but a pitch black shot [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1000 2541 1024 1037 2686 18735 1000 2003 2275 1999 2541 1998 1996 2364 2839 2003 11085 1012 1037 3274 1012 2008 1005 1055 2157 1010 1037 3274 2040 7566 1998 6732 4498 2006 2049 2219 1012 2023 2001 2081 1999 3380 1998 2000 2228 2011 2541 2009 2052 2022 9530 3401 11444 3468 2008 7588 2052 2831 2003 1037 8257 1012 2065 2023 2001 1999 24622 2549 1010 1037 3331 3274 2008 2018 6699 1998 2081 2049 2219 6567 2052 2022 2641 2074 2004 22822 12356 2004 2023 1012 2045 2003 2498 1999 2023 2143 2008 27895 2015 2151 2785 1997 7603 1012 2009 27895 2015 2048 9597 1998 2028 2003 2170 1024 3637 1012 2009 4627 2007 2498 1010 2021 1037 6510 2304 2915 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.003881 140467944662912 run_classifier.py:465] input_ids: 101 1000 2541 1024 1037 2686 18735 1000 2003 2275 1999 2541 1998 1996 2364 2839 2003 11085 1012 1037 3274 1012 2008 1005 1055 2157 1010 1037 3274 2040 7566 1998 6732 4498 2006 2049 2219 1012 2023 2001 2081 1999 3380 1998 2000 2228 2011 2541 2009 2052 2022 9530 3401 11444 3468 2008 7588 2052 2831 2003 1037 8257 1012 2065 2023 2001 1999 24622 2549 1010 1037 3331 3274 2008 2018 6699 1998 2081 2049 2219 6567 2052 2022 2641 2074 2004 22822 12356 2004 2023 1012 2045 2003 2498 1999 2023 2143 2008 27895 2015 2151 2785 1997 7603 1012 2009 27895 2015 2048 9597 1998 2028 2003 2170 1024 3637 1012 2009 4627 2007 2498 1010 2021 1037 6510 2304 2915 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.006738 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.010988 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.013406 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.022435 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.024860 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the gilmore girls is about a mother who had a daughter when she was 16 . now the daughter is 16 ( in season 1 ) and they live like sisters . sharing everything , trusting each other completely . < br / > < br / > i like the gilmore girls but i am not sure why . the mother , named lore ##lai ( lauren graham ) , and the daughter , named rory ( short for lore ##lai , played by alexis bled ##el ) , are both very beautiful women , they are both funny and they are charming in their own ways . there are some funny supporting characters , such as luke ( scott patterson ) . he and [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.026714 140467944662912 run_classifier.py:464] tokens: [CLS] the gilmore girls is about a mother who had a daughter when she was 16 . now the daughter is 16 ( in season 1 ) and they live like sisters . sharing everything , trusting each other completely . < br / > < br / > i like the gilmore girls but i am not sure why . the mother , named lore ##lai ( lauren graham ) , and the daughter , named rory ( short for lore ##lai , played by alexis bled ##el ) , are both very beautiful women , they are both funny and they are charming in their own ways . there are some funny supporting characters , such as luke ( scott patterson ) . he and [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 22999 3057 2003 2055 1037 2388 2040 2018 1037 2684 2043 2016 2001 2385 1012 2085 1996 2684 2003 2385 1006 1999 2161 1015 1007 1998 2027 2444 2066 5208 1012 6631 2673 1010 19836 2169 2060 3294 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2066 1996 22999 3057 2021 1045 2572 2025 2469 2339 1012 1996 2388 1010 2315 19544 19771 1006 10294 5846 1007 1010 1998 1996 2684 1010 2315 14285 1006 2460 2005 19544 19771 1010 2209 2011 13573 23919 2884 1007 1010 2024 2119 2200 3376 2308 1010 2027 2024 2119 6057 1998 2027 2024 11951 1999 2037 2219 3971 1012 2045 2024 2070 6057 4637 3494 1010 2107 2004 5355 1006 3660 12424 1007 1012 2002 1998 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.028832 140467944662912 run_classifier.py:465] input_ids: 101 1996 22999 3057 2003 2055 1037 2388 2040 2018 1037 2684 2043 2016 2001 2385 1012 2085 1996 2684 2003 2385 1006 1999 2161 1015 1007 1998 2027 2444 2066 5208 1012 6631 2673 1010 19836 2169 2060 3294 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2066 1996 22999 3057 2021 1045 2572 2025 2469 2339 1012 1996 2388 1010 2315 19544 19771 1006 10294 5846 1007 1010 1998 1996 2684 1010 2315 14285 1006 2460 2005 19544 19771 1010 2209 2011 13573 23919 2884 1007 1010 2024 2119 2200 3376 2308 1010 2027 2024 2119 6057 1998 2027 2024 11951 1999 2037 2219 3971 1012 2045 2024 2070 6057 4637 3494 1010 2107 2004 5355 1006 3660 12424 1007 1012 2002 1998 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.031815 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.034070 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.036373 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.059420 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.061529 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] based on actual events of 1905 , silent film the battleship pot ##em ##kin concerns an imperial russian ship on which ab ##omi ##nable conditions lead to a mutiny . shocked by conditions on the ship , citizens of the port city odessa rally to the mu ##tine ##ers ' support - - and in consequence find themselves at the mercy of imperial forces , who attack the civilian supporters with savage force . < br / > < br / > pot ##em ##kin is a film in which individual characters are much less important than the groups and crowds of which they are members , and it achieve ##s its incredible power by showing the clash of the groups and crowds in a series [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.063688 140467944662912 run_classifier.py:464] tokens: [CLS] based on actual events of 1905 , silent film the battleship pot ##em ##kin concerns an imperial russian ship on which ab ##omi ##nable conditions lead to a mutiny . shocked by conditions on the ship , citizens of the port city odessa rally to the mu ##tine ##ers ' support - - and in consequence find themselves at the mercy of imperial forces , who attack the civilian supporters with savage force . < br / > < br / > pot ##em ##kin is a film in which individual characters are much less important than the groups and crowds of which they are members , and it achieve ##s its incredible power by showing the clash of the groups and crowds in a series [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2241 2006 5025 2824 1997 5497 1010 4333 2143 1996 17224 8962 6633 4939 5936 2019 4461 2845 2911 2006 2029 11113 20936 22966 3785 2599 2000 1037 19306 1012 7135 2011 3785 2006 1996 2911 1010 4480 1997 1996 3417 2103 19693 8320 2000 1996 14163 10196 2545 1005 2490 1011 1011 1998 1999 9509 2424 3209 2012 1996 8673 1997 4461 2749 1010 2040 2886 1996 6831 6793 2007 9576 2486 1012 1026 7987 1013 1028 1026 7987 1013 1028 8962 6633 4939 2003 1037 2143 1999 2029 3265 3494 2024 2172 2625 2590 2084 1996 2967 1998 12783 1997 2029 2027 2024 2372 1010 1998 2009 6162 2015 2049 9788 2373 2011 4760 1996 13249 1997 1996 2967 1998 12783 1999 1037 2186 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.066058 140467944662912 run_classifier.py:465] input_ids: 101 2241 2006 5025 2824 1997 5497 1010 4333 2143 1996 17224 8962 6633 4939 5936 2019 4461 2845 2911 2006 2029 11113 20936 22966 3785 2599 2000 1037 19306 1012 7135 2011 3785 2006 1996 2911 1010 4480 1997 1996 3417 2103 19693 8320 2000 1996 14163 10196 2545 1005 2490 1011 1011 1998 1999 9509 2424 3209 2012 1996 8673 1997 4461 2749 1010 2040 2886 1996 6831 6793 2007 9576 2486 1012 1026 7987 1013 1028 1026 7987 1013 1028 8962 6633 4939 2003 1037 2143 1999 2029 3265 3494 2024 2172 2625 2590 2084 1996 2967 1998 12783 1997 2029 2027 2024 2372 1010 1998 2009 6162 2015 2049 9788 2373 2011 4760 1996 13249 1997 1996 2967 1998 12783 1999 1037 2186 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.068142 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.070387 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.072402 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.080017 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.082493 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] fritz lang directed two great western ##s : \" western union \" and \" the return of frank james \" . the frank james movie equals \" jesse james \" . \" western union \" is one of randolph scott ' s great western ##s . i have never seen robert young in a western before ; he is terrific as the telegraph employee . this is the only movie i can think of that is about the telegraph company opening up in the west . it is a high - geared story about the telegraph in the west , a triangle love story , and about loyalty . < br / > < br / > the supporting cast is superb . dean jagger , [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.084684 140467944662912 run_classifier.py:464] tokens: [CLS] fritz lang directed two great western ##s : \" western union \" and \" the return of frank james \" . the frank james movie equals \" jesse james \" . \" western union \" is one of randolph scott ' s great western ##s . i have never seen robert young in a western before ; he is terrific as the telegraph employee . this is the only movie i can think of that is about the telegraph company opening up in the west . it is a high - geared story about the telegraph in the west , a triangle love story , and about loyalty . < br / > < br / > the supporting cast is superb . dean jagger , [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12880 11374 2856 2048 2307 2530 2015 1024 1000 2530 2586 1000 1998 1000 1996 2709 1997 3581 2508 1000 1012 1996 3581 2508 3185 19635 1000 7627 2508 1000 1012 1000 2530 2586 1000 2003 2028 1997 13031 3660 1005 1055 2307 2530 2015 1012 1045 2031 2196 2464 2728 2402 1999 1037 2530 2077 1025 2002 2003 27547 2004 1996 10013 7904 1012 2023 2003 1996 2069 3185 1045 2064 2228 1997 2008 2003 2055 1996 10013 2194 3098 2039 1999 1996 2225 1012 2009 2003 1037 2152 1011 23636 2466 2055 1996 10013 1999 1996 2225 1010 1037 9546 2293 2466 1010 1998 2055 9721 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4637 3459 2003 21688 1012 4670 25827 1010 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.087009 140467944662912 run_classifier.py:465] input_ids: 101 12880 11374 2856 2048 2307 2530 2015 1024 1000 2530 2586 1000 1998 1000 1996 2709 1997 3581 2508 1000 1012 1996 3581 2508 3185 19635 1000 7627 2508 1000 1012 1000 2530 2586 1000 2003 2028 1997 13031 3660 1005 1055 2307 2530 2015 1012 1045 2031 2196 2464 2728 2402 1999 1037 2530 2077 1025 2002 2003 27547 2004 1996 10013 7904 1012 2023 2003 1996 2069 3185 1045 2064 2228 1997 2008 2003 2055 1996 10013 2194 3098 2039 1999 1996 2225 1012 2009 2003 1037 2152 1011 23636 2466 2055 1996 10013 1999 1996 2225 1010 1037 9546 2293 2466 1010 1998 2055 9721 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4637 3459 2003 21688 1012 4670 25827 1010 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.089092 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.091032 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.092986 140467944662912 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.110715 140467944662912 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.112915 140467944662912 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this comment is meant mainly as a warning to the people who might be attracted to the title by its ( temporarily ) high user rating which i find frankly pu ##zzling . the reasons why i didn ' t like this title are following : < br / > < br / > 1 . the direct ##er must have had some doubts whether to make a jackie - chan - type of a flick or a dark o ##ed ##ip ##ian tragedy . as a result , in terms of genre , the film falls between two stool ##s , as the tragic and comic elements clash and cancel out each other rather than make a harmon ##ious whole . < br / > [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.114844 140467944662912 run_classifier.py:464] tokens: [CLS] this comment is meant mainly as a warning to the people who might be attracted to the title by its ( temporarily ) high user rating which i find frankly pu ##zzling . the reasons why i didn ' t like this title are following : < br / > < br / > 1 . the direct ##er must have had some doubts whether to make a jackie - chan - type of a flick or a dark o ##ed ##ip ##ian tragedy . as a result , in terms of genre , the film falls between two stool ##s , as the tragic and comic elements clash and cancel out each other rather than make a harmon ##ious whole . < br / > [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 7615 2003 3214 3701 2004 1037 5432 2000 1996 2111 2040 2453 2022 6296 2000 1996 2516 2011 2049 1006 8184 1007 2152 5310 5790 2029 1045 2424 19597 16405 20838 1012 1996 4436 2339 1045 2134 1005 1056 2066 2023 2516 2024 2206 1024 1026 7987 1013 1028 1026 7987 1013 1028 1015 1012 1996 3622 2121 2442 2031 2018 2070 13579 3251 2000 2191 1037 9901 1011 9212 1011 2828 1997 1037 17312 2030 1037 2601 1051 2098 11514 2937 10576 1012 2004 1037 2765 1010 1999 3408 1997 6907 1010 1996 2143 4212 2090 2048 14708 2015 1010 2004 1996 13800 1998 5021 3787 13249 1998 17542 2041 2169 2060 2738 2084 2191 1037 25546 6313 2878 1012 1026 7987 1013 1028 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.117447 140467944662912 run_classifier.py:465] input_ids: 101 2023 7615 2003 3214 3701 2004 1037 5432 2000 1996 2111 2040 2453 2022 6296 2000 1996 2516 2011 2049 1006 8184 1007 2152 5310 5790 2029 1045 2424 19597 16405 20838 1012 1996 4436 2339 1045 2134 1005 1056 2066 2023 2516 2024 2206 1024 1026 7987 1013 1028 1026 7987 1013 1028 1015 1012 1996 3622 2121 2442 2031 2018 2070 13579 3251 2000 2191 1037 9901 1011 9212 1011 2828 1997 1037 17312 2030 1037 2601 1051 2098 11514 2937 10576 1012 2004 1037 2765 1010 1999 3408 1997 6907 1010 1996 2143 4212 2090 2048 14708 2015 1010 2004 1996 13800 1998 5021 3787 13249 1998 17542 2041 2169 2060 2738 2084 2191 1037 25546 6313 2878 1012 1026 7987 1013 1028 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.119683 140467944662912 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.121885 140467944662912 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:09.123697 140467944662912 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0a20e8278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:31.988286 140467944662912 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0a20e8278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:32.275648 140467944662912 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:35.329490 140467944662912 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:44.461430 140467944662912 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:44.464919 140467944662912 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:45.940525 140467944662912 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:50.637558 140467944662912 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:50.901015 140467944662912 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:38:59.261064 140467944662912 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7334579, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:39:14.645087 140467944662912 basic_session_run_hooks.py:249] loss = 0.7334579, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 46 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:39:57.090178 140467944662912 basic_session_run_hooks.py:594] Saving checkpoints for 46 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.33225253.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:06.486405 140467944662912 estimator.py:359] Loss for final step: 0.33225253.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:09.087566 140467944662912 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:12.668329 140467944662912 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:21.597305 140467944662912 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-30T06:40:21Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:21.622639 140467944662912 evaluation.py:257] Starting evaluation at 2019-05-30T06:40:21Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:23.515932 140467944662912 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:23.527793 140467944662912 saver.py:1270] Restoring parameters from output/model.ckpt-46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:25.950911 140467944662912 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:40:26.221749 140467944662912 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-30-06:41:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:41:12.178606 140467944662912 evaluation.py:277] Finished evaluation at 2019-05-30-06:41:12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 46: auc = 0.7777804, eval_accuracy = 0.7784, f1_score = 0.8027065, false_negatives = 259.0, false_positives = 849.0, global_step = 46, loss = 0.50345117, precision = 0.7263938, recall = 0.89693594, true_negatives = 1638.0, true_positives = 2254.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:41:12.180522 140467944662912 estimator.py:1979] Saving dict for global step 46: auc = 0.7777804, eval_accuracy = 0.7784, f1_score = 0.8027065, false_negatives = 259.0, false_positives = 849.0, global_step = 46, loss = 0.50345117, precision = 0.7263938, recall = 0.89693594, true_negatives = 1638.0, true_positives = 2254.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 46: output/model.ckpt-46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 06:41:12.189347 140467944662912 estimator.py:2039] Saving 'checkpoint_path' summary for global step 46: output/model.ckpt-46\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOvtveTMqwp",
        "colab_type": "code",
        "outputId": "c1dfa177-0687-4f8a-dcb5-aaf0ca47563e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# This is the result with learning rate of 2e-5\n",
        "pretty_print(result)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>auc</th>\n",
              "      <td>0.777780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.778400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.802706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_negatives</th>\n",
              "      <td>259.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_positives</th>\n",
              "      <td>849.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>global_step</th>\n",
              "      <td>46.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.503451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.726394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.896936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_negatives</th>\n",
              "      <td>1638.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_positives</th>\n",
              "      <td>2254.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      values\n",
              "auc                 0.777780\n",
              "eval_accuracy       0.778400\n",
              "f1_score            0.802706\n",
              "false_negatives   259.000000\n",
              "false_positives   849.000000\n",
              "global_step        46.000000\n",
              "loss                0.503451\n",
              "precision           0.726394\n",
              "recall              0.896936\n",
              "true_negatives   1638.000000\n",
              "true_positives   2254.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OPTDcGMsJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the result with learning rate of 1e-4\n",
        "pretty_print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}