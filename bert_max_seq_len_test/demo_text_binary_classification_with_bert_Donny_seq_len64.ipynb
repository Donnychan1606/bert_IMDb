{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-text-binary-classification-with-bert-Donny.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donnychan1606/bert_IMDb/blob/master/demo_text_binary_classification_with_bert_Donny_seq_len64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbAMqZ6IZuw",
        "colab_type": "text"
      },
      "source": [
        "base code borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
        "\n",
        "Refactored by [Shuyi Wang](https://www.linkedin.com/in/shuyi-wang-b3955026/)\n",
        "\n",
        "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "trusted": true,
        "outputId": "ce60f75e-a6e3-46e0-e149-2942a8bee9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e9d0bdb1-0b60-4830-d4ae-5fd08f7378d0"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0530 11:09:39.423482 139659932899200 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZM71PjIOF_I",
        "colab": {}
      },
      "source": [
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCYOL8HbIZu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(bert_model_hub)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      bert_model_hub,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "      bert_model_hub = bert_model_hub,\n",
        "      num_labels=len(label_list),\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, \n",
        "               MAX_SEQ_LENGTH = 64,\n",
        "              BATCH_SIZE = 32,\n",
        "              LEARNING_RATE = 2e-5,\n",
        "              NUM_TRAIN_EPOCHS = 3.0,\n",
        "              WARMUP_PROPORTION = 0.1,\n",
        "              SAVE_SUMMARY_STEPS = 100,\n",
        "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
        "              bert_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"):\n",
        "\n",
        "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
        "    \n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "                                  bert_model_hub, \n",
        "                                  OUTPUT_DIR, \n",
        "                                  SAVE_SUMMARY_STEPS, \n",
        "                                  SAVE_CHECKPOINTS_STEPS, \n",
        "                                  label_list, \n",
        "                                  LEARNING_RATE, \n",
        "                                  num_train_steps, \n",
        "                                  num_warmup_steps, \n",
        "                                  BATCH_SIZE)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    return result_dict, estimator\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wpUHTA8LIZu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qmP8MBvjIZvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = 'output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV3ExI2JJMhd",
        "colab_type": "text"
      },
      "source": [
        "----- you just need to focus from here ------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUjVoFtJVEO",
        "colab_type": "text"
      },
      "source": [
        "## Get your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ6CestJXZK",
        "colab_type": "code",
        "outputId": "0dffdcbd-32ea-4a16-df5d-ae91b25a4201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-30 11:10:09--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12909082 (12M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-30 11:10:09 (87.3 MB/s) - ‘test.csv’ saved [12909082/12909082]\n",
            "\n",
            "--2019-05-30 11:10:11--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43221547 (41M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  41.22M   135MB/s    in 0.3s    \n",
            "\n",
            "2019-05-30 11:10:11 (135 MB/s) - ‘train.csv’ saved [43221547/43221547]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFBwDlmnIZvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tju0c4dqIZvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8i4a5xUFfe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9BAxyKhKirc",
        "colab_type": "code",
        "outputId": "34ce0f7b-7b1d-4c66-d6fd-b5b9801af794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19345</th>\n",
              "      <td>This film has, over the past ten years, become...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14547</th>\n",
              "      <td>Spirit: Stallion of the Cimarron is an overall...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28258</th>\n",
              "      <td>I've read all the complimentary posts on this ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>Its not the cast. A finer group of actors, you...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4863</th>\n",
              "      <td>An archaeologist (Casper Van Dien) stumbles ac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "19345  This film has, over the past ten years, become...      1\n",
              "14547  Spirit: Stallion of the Cimarron is an overall...      1\n",
              "28258  I've read all the complimentary posts on this ...      0\n",
              "1666   Its not the cast. A finer group of actors, you...      0\n",
              "4863   An archaeologist (Casper Van Dien) stumbles ac...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDh-VkaxIcJq",
        "colab_type": "code",
        "outputId": "04e01d5b-b824-4f81-eb7d-a5b576717142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape\n",
        "#test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUuX8u8Itdc",
        "colab_type": "code",
        "outputId": "3c406b1d-dc01-43b0-8e44-30a8908555ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM8M7k0gKk5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myparam = {\n",
        "        \"DATA_COLUMN\": \"review\",\n",
        "        \"LABEL_COLUMN\": \"label\",\n",
        "        \"LEARNING_RATE\": 2e-5,\n",
        "        \"NUM_TRAIN_EPOCHS\":3\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg2apeXpMqG-",
        "outputId": "84aea52c-89ea-401c-b9df-188ec626ef56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6446
        }
      },
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:10:38.355288 139659932899200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:40.660333 139659932899200 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.802681 139659932899200 run_classifier.py:774] Writing example 0 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.815868 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.817713 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this film has , over the past ten years , become one of my favorite pseudo noir experiences . the three storyline threads given us by kazan each have their unique and separate pleasures . the domestic chi ##tch ##at between bel ge ##dd ##es and wi ##dm ##ark , the movement between rooms , the small gestures such as the phone [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.819663 139659932899200 run_classifier.py:464] tokens: [CLS] this film has , over the past ten years , become one of my favorite pseudo noir experiences . the three storyline threads given us by kazan each have their unique and separate pleasures . the domestic chi ##tch ##at between bel ge ##dd ##es and wi ##dm ##ark , the movement between rooms , the small gestures such as the phone [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2143 2038 1010 2058 1996 2627 2702 2086 1010 2468 2028 1997 2026 5440 18404 15587 6322 1012 1996 2093 9994 16457 2445 2149 2011 22001 2169 2031 2037 4310 1998 3584 26552 1012 1996 4968 9610 10649 4017 2090 19337 16216 14141 2229 1998 15536 22117 17007 1010 1996 2929 2090 4734 1010 1996 2235 18327 2107 2004 1996 3042 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.821485 139659932899200 run_classifier.py:465] input_ids: 101 2023 2143 2038 1010 2058 1996 2627 2702 2086 1010 2468 2028 1997 2026 5440 18404 15587 6322 1012 1996 2093 9994 16457 2445 2149 2011 22001 2169 2031 2037 4310 1998 3584 26552 1012 1996 4968 9610 10649 4017 2090 19337 16216 14141 2229 1998 15536 22117 17007 1010 1996 2929 2090 4734 1010 1996 2235 18327 2107 2004 1996 3042 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.824150 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.827331 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.830367 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.847259 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.849307 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] spirit : stallion of the ci ##mar ##ron is an overall wonderful movie . the blending of animation types is unique , the storyline is amazing , and the music is wonderful . < br / > < br / > the drawn animation is a special thing about many animation ##s . how they expressed the characters , especially the horses [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.850998 139659932899200 run_classifier.py:464] tokens: [CLS] spirit : stallion of the ci ##mar ##ron is an overall wonderful movie . the blending of animation types is unique , the storyline is amazing , and the music is wonderful . < br / > < br / > the drawn animation is a special thing about many animation ##s . how they expressed the characters , especially the horses [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4382 1024 19122 1997 1996 25022 7849 4948 2003 2019 3452 6919 3185 1012 1996 23293 1997 7284 4127 2003 4310 1010 1996 9994 2003 6429 1010 1998 1996 2189 2003 6919 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4567 7284 2003 1037 2569 2518 2055 2116 7284 2015 1012 2129 2027 5228 1996 3494 1010 2926 1996 5194 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.853412 139659932899200 run_classifier.py:465] input_ids: 101 4382 1024 19122 1997 1996 25022 7849 4948 2003 2019 3452 6919 3185 1012 1996 23293 1997 7284 4127 2003 4310 1010 1996 9994 2003 6429 1010 1998 1996 2189 2003 6919 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4567 7284 2003 1037 2569 2518 2055 2116 7284 2015 1012 2129 2027 5228 1996 3494 1010 2926 1996 5194 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.856162 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.858773 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.861337 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.877099 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.880379 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i ' ve read all the compliment ##ary posts on this mud ##dled semi - noir and am puzzled at the high regard for what seems , in the cruel light of 2007 , a very sloppy late - r ##ko assembly - line product . all that endless documentary footage of fish , waves , fish , waves has little to [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.882879 139659932899200 run_classifier.py:464] tokens: [CLS] i ' ve read all the compliment ##ary posts on this mud ##dled semi - noir and am puzzled at the high regard for what seems , in the cruel light of 2007 , a very sloppy late - r ##ko assembly - line product . all that endless documentary footage of fish , waves , fish , waves has little to [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 1005 2310 3191 2035 1996 19394 5649 8466 2006 2023 8494 20043 4100 1011 15587 1998 2572 14909 2012 1996 2152 7634 2005 2054 3849 1010 1999 1996 10311 2422 1997 2289 1010 1037 2200 28810 2397 1011 1054 3683 3320 1011 2240 4031 1012 2035 2008 10866 4516 8333 1997 3869 1010 5975 1010 3869 1010 5975 2038 2210 2000 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.884895 139659932899200 run_classifier.py:465] input_ids: 101 1045 1005 2310 3191 2035 1996 19394 5649 8466 2006 2023 8494 20043 4100 1011 15587 1998 2572 14909 2012 1996 2152 7634 2005 2054 3849 1010 1999 1996 10311 2422 1997 2289 1010 1037 2200 28810 2397 1011 1054 3683 3320 1011 2240 4031 1012 2035 2008 10866 4516 8333 1997 3869 1010 5975 1010 3869 1010 5975 2038 2210 2000 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.886895 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.888802 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.890523 139659932899200 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.896229 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.898073 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] its not the cast . a finer group of actors , you could not find . its not the setting . the director is in love with new york city , and by the end of the film , so are we all ! woody allen could not improve upon what bog ##don ##ovich has done here . if you are going [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.900057 139659932899200 run_classifier.py:464] tokens: [CLS] its not the cast . a finer group of actors , you could not find . its not the setting . the director is in love with new york city , and by the end of the film , so are we all ! woody allen could not improve upon what bog ##don ##ovich has done here . if you are going [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2049 2025 1996 3459 1012 1037 26954 2177 1997 5889 1010 2017 2071 2025 2424 1012 2049 2025 1996 4292 1012 1996 2472 2003 1999 2293 2007 2047 2259 2103 1010 1998 2011 1996 2203 1997 1996 2143 1010 2061 2024 2057 2035 999 13703 5297 2071 2025 5335 2588 2054 22132 5280 12303 2038 2589 2182 1012 2065 2017 2024 2183 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.901840 139659932899200 run_classifier.py:465] input_ids: 101 2049 2025 1996 3459 1012 1037 26954 2177 1997 5889 1010 2017 2071 2025 2424 1012 2049 2025 1996 4292 1012 1996 2472 2003 1999 2293 2007 2047 2259 2103 1010 1998 2011 1996 2203 1997 1996 2143 1010 2061 2024 2057 2035 999 13703 5297 2071 2025 5335 2588 2054 22132 5280 12303 2038 2589 2182 1012 2065 2017 2024 2183 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.903706 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.905598 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.907221 139659932899200 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.914646 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.916712 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] an archaeologist ( casper van die ##n ) stumble ##s accidentally upon an ancient , 40 foot mummy , well preserved underground in the nevada desert . they are determined to keep this a secret and call in a jewish translator to assist in figuring out the history of it . the mummy , as explained at the beginning , is the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.918517 139659932899200 run_classifier.py:464] tokens: [CLS] an archaeologist ( casper van die ##n ) stumble ##s accidentally upon an ancient , 40 foot mummy , well preserved underground in the nevada desert . they are determined to keep this a secret and call in a jewish translator to assist in figuring out the history of it . the mummy , as explained at the beginning , is the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2019 18821 1006 24602 3158 3280 2078 1007 21811 2015 9554 2588 2019 3418 1010 2871 3329 22788 1010 2092 6560 5230 1999 1996 7756 5532 1012 2027 2024 4340 2000 2562 2023 1037 3595 1998 2655 1999 1037 3644 11403 2000 6509 1999 23218 2041 1996 2381 1997 2009 1012 1996 22788 1010 2004 4541 2012 1996 2927 1010 2003 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.920069 139659932899200 run_classifier.py:465] input_ids: 101 2019 18821 1006 24602 3158 3280 2078 1007 21811 2015 9554 2588 2019 3418 1010 2871 3329 22788 1010 2092 6560 5230 1999 1996 7756 5532 1012 2027 2024 4340 2000 2562 2023 1037 3595 1998 2655 1999 1037 3644 11403 2000 6509 1999 23218 2041 1996 2381 1997 2009 1012 1996 22788 1010 2004 4541 2012 1996 2927 1010 2003 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.921916 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.923699 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:10:43.925593 139659932899200 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:11:31.739565 139659932899200 run_classifier.py:774] Writing example 10000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:12:19.756873 139659932899200 run_classifier.py:774] Writing example 20000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:07.517519 139659932899200 run_classifier.py:774] Writing example 30000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.817394 139659932899200 run_classifier.py:774] Writing example 0 of 10000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.823395 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.825228 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.827552 139659932899200 run_classifier.py:464] tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.830326 139659932899200 run_classifier.py:465] input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.834098 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.836008 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.841033 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.856834 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.858564 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.860318 139659932899200 run_classifier.py:464] tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.863065 139659932899200 run_classifier.py:465] input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.865578 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.867491 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.869671 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.880206 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.882216 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.884857 139659932899200 run_classifier.py:464] tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.886830 139659932899200 run_classifier.py:465] input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.888748 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.890953 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.892787 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.898545 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.900529 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.903126 139659932899200 run_classifier.py:464] tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.905073 139659932899200 run_classifier.py:465] input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.907305 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.908716 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.910312 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.918174 139659932899200 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.920917 139659932899200 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.922792 139659932899200 run_classifier.py:464] tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.924655 139659932899200 run_classifier.py:465] input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.926522 139659932899200 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.928807 139659932899200 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:13:19.930706 139659932899200 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04b2a0b898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:05.697387 139659932899200 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04b2a0b898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:14.350520 139659932899200 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:17.407215 139659932899200 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:14:17.533673 139659932899200 deprecation.py:506] From <ipython-input-5-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:14:17.580154 139659932899200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:14:17.946562 139659932899200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:14:26.176399 139659932899200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:28.802790 139659932899200 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:28.806560 139659932899200 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:32.697061 139659932899200 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:37.556200 139659932899200 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:37.763680 139659932899200 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:14:51.449435 139659932899200 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7988913, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:15:07.843141 139659932899200 basic_session_run_hooks.py:249] loss = 0.7988913, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.68158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:16:07.310179 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 1.68158\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.62048393, step = 100 (59.472 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:16:07.315064 139659932899200 basic_session_run_hooks.py:247] loss = 0.62048393, step = 100 (59.472 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:16:54.436109 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12197\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.37955147, step = 200 (47.124 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:16:54.438804 139659932899200 basic_session_run_hooks.py:247] loss = 0.37955147, step = 200 (47.124 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:17:41.725133 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11466\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.66334563, step = 300 (47.289 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:17:41.727934 139659932899200 basic_session_run_hooks.py:247] loss = 0.66334563, step = 300 (47.289 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:18:28.891440 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12016\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.45497227, step = 400 (47.166 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:18:28.893777 139659932899200 basic_session_run_hooks.py:247] loss = 0.45497227, step = 400 (47.166 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:19:16.106708 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11796\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.34170502, step = 500 (47.216 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:19:16.109374 139659932899200 basic_session_run_hooks.py:247] loss = 0.34170502, step = 500 (47.216 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:20:03.300194 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11894\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.4324513, step = 600 (47.193 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:20:03.302675 139659932899200 basic_session_run_hooks.py:247] loss = 0.4324513, step = 600 (47.193 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:20:50.499514 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11867\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3569498, step = 700 (47.203 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:20:50.506148 139659932899200 basic_session_run_hooks.py:247] loss = 0.3569498, step = 700 (47.203 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:21:37.689658 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11909\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.15607353, step = 800 (47.189 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:21:37.694910 139659932899200 basic_session_run_hooks.py:247] loss = 0.15607353, step = 800 (47.189 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:22:24.861442 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11991\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.669831, step = 900 (47.173 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:22:24.867568 139659932899200 basic_session_run_hooks.py:247] loss = 0.669831, step = 900 (47.173 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:23:12.076386 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11797\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.30842435, step = 1000 (47.214 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:23:12.081339 139659932899200 basic_session_run_hooks.py:247] loss = 0.30842435, step = 1000 (47.214 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:23:59.341493 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11572\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20202589, step = 1100 (47.263 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:23:59.344499 139659932899200 basic_session_run_hooks.py:247] loss = 0.20202589, step = 1100 (47.263 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:24:46.530966 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11912\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16318029, step = 1200 (47.189 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:24:46.533298 139659932899200 basic_session_run_hooks.py:247] loss = 0.16318029, step = 1200 (47.189 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:25:33.641095 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12269\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.051885683, step = 1300 (47.113 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:25:33.646666 139659932899200 basic_session_run_hooks.py:247] loss = 0.051885683, step = 1300 (47.113 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:26:20.817761 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11969\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0544776, step = 1400 (47.174 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:26:20.820367 139659932899200 basic_session_run_hooks.py:247] loss = 0.0544776, step = 1400 (47.174 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:27:08.037587 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11775\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.077511854, step = 1500 (47.222 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:27:08.042488 139659932899200 basic_session_run_hooks.py:247] loss = 0.077511854, step = 1500 (47.222 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:27:55.286377 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11646\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.1869879, step = 1600 (47.247 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:27:55.289174 139659932899200 basic_session_run_hooks.py:247] loss = 0.1869879, step = 1600 (47.247 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:28:42.433509 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16448632, step = 1700 (47.147 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:28:42.435988 139659932899200 basic_session_run_hooks.py:247] loss = 0.16448632, step = 1700 (47.147 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:29:29.599545 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12017\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08454014, step = 1800 (47.166 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:29:29.602206 139659932899200 basic_session_run_hooks.py:247] loss = 0.08454014, step = 1800 (47.166 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.1189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:30:16.793829 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.1189\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.083818845, step = 1900 (47.195 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:30:16.797519 139659932899200 basic_session_run_hooks.py:247] loss = 0.083818845, step = 1900 (47.195 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:31:04.044598 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11636\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.23015499, step = 2000 (47.251 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:31:04.048372 139659932899200 basic_session_run_hooks.py:247] loss = 0.23015499, step = 2000 (47.251 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:31:51.348202 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11401\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.081649095, step = 2100 (47.302 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:31:51.350599 139659932899200 basic_session_run_hooks.py:247] loss = 0.081649095, step = 2100 (47.302 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:32:38.618525 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11549\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.007796857, step = 2200 (47.273 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:32:38.623927 139659932899200 basic_session_run_hooks.py:247] loss = 0.007796857, step = 2200 (47.273 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:33:25.786873 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12007\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.23638505, step = 2300 (47.169 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:33:25.793063 139659932899200 basic_session_run_hooks.py:247] loss = 0.23638505, step = 2300 (47.169 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:34:12.950561 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12027\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0040885718, step = 2400 (47.162 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:34:12.955523 139659932899200 basic_session_run_hooks.py:247] loss = 0.0040885718, step = 2400 (47.162 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:35:00.073234 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12212\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.007681685, step = 2500 (47.120 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:35:00.075659 139659932899200 basic_session_run_hooks.py:247] loss = 0.007681685, step = 2500 (47.120 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:35:47.300906 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11741\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.03018838, step = 2600 (47.230 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:35:47.306139 139659932899200 basic_session_run_hooks.py:247] loss = 0.03018838, step = 2600 (47.230 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.1211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:36:34.446250 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.1211\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.10237075, step = 2700 (47.145 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:36:34.450618 139659932899200 basic_session_run_hooks.py:247] loss = 0.10237075, step = 2700 (47.145 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.12077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:37:21.599073 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.12077\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.012911722, step = 2800 (47.153 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:37:21.604472 139659932899200 basic_session_run_hooks.py:247] loss = 0.012911722, step = 2800 (47.153 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:38:08.807586 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11826\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0013475141, step = 2900 (47.209 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:38:08.812404 139659932899200 basic_session_run_hooks.py:247] loss = 0.0013475141, step = 2900 (47.209 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.11343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:38:56.124125 139659932899200 basic_session_run_hooks.py:680] global_step/sec: 2.11343\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0017030773, step = 3000 (47.316 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:38:56.128080 139659932899200 basic_session_run_hooks.py:247] loss = 0.0017030773, step = 3000 (47.316 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3046 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:17.395036 139659932899200 basic_session_run_hooks.py:594] Saving checkpoints for 3046 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.007737907.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:27.219077 139659932899200 estimator.py:359] Loss for final step: 0.007737907.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:29.814148 139659932899200 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:33.576846 139659932899200 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:42.390309 139659932899200 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-30T11:39:42Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:42.413932 139659932899200 evaluation.py:257] Starting evaluation at 2019-05-30T11:39:42Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:44.301417 139659932899200 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 11:39:44.310515 139659932899200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-3046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:44.319104 139659932899200 saver.py:1270] Restoring parameters from output/model.ckpt-3046\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:46.495878 139659932899200 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:39:46.735798 139659932899200 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-30-11:40:33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:40:33.033261 139659932899200 evaluation.py:277] Finished evaluation at 2019-05-30-11:40:33\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 3046: auc = 0.84110004, eval_accuracy = 0.8411, f1_score = 0.8506719, false_negatives = 474.0, false_positives = 1115.0, global_step = 3046, loss = 0.7008142, precision = 0.80234003, recall = 0.9052, true_negatives = 3885.0, true_positives = 4526.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:40:33.035469 139659932899200 estimator.py:1979] Saving dict for global step 3046: auc = 0.84110004, eval_accuracy = 0.8411, f1_score = 0.8506719, false_negatives = 474.0, false_positives = 1115.0, global_step = 3046, loss = 0.7008142, precision = 0.80234003, recall = 0.9052, true_negatives = 3885.0, true_positives = 4526.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3046: output/model.ckpt-3046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 11:40:35.394481 139659932899200 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3046: output/model.ckpt-3046\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOvtveTMqwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "80b79e60-74a5-4cd6-9ada-29e57f3bd503"
      },
      "source": [
        "# This is the result with learning rate of 2e-5\n",
        "pretty_print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>auc</th>\n",
              "      <td>0.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.850672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_negatives</th>\n",
              "      <td>474.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_positives</th>\n",
              "      <td>1115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>global_step</th>\n",
              "      <td>3046.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.700814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.802340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.905200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_negatives</th>\n",
              "      <td>3885.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_positives</th>\n",
              "      <td>4526.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      values\n",
              "auc                 0.841100\n",
              "eval_accuracy       0.841100\n",
              "f1_score            0.850672\n",
              "false_negatives   474.000000\n",
              "false_positives  1115.000000\n",
              "global_step      3046.000000\n",
              "loss                0.700814\n",
              "precision           0.802340\n",
              "recall              0.905200\n",
              "true_negatives   3885.000000\n",
              "true_positives   4526.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OPTDcGMsJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the result with learning rate of 1e-4\n",
        "pretty_print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}