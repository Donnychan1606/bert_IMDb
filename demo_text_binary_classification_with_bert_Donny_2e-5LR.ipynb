{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-text-binary-classification-with-bert-Donny.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donnychan1606/bert_IMDb/blob/master/demo_text_binary_classification_with_bert_Donny_2e-5LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbAMqZ6IZuw",
        "colab_type": "text"
      },
      "source": [
        "base code borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
        "\n",
        "Refactored by [Shuyi Wang](https://www.linkedin.com/in/shuyi-wang-b3955026/)\n",
        "\n",
        "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "29643e82-400b-4ee5-85da-bfabcda7ce62"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e760499d-268e-4fb5-844f-8774d1c13a40"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0529 22:33:12.476005 140576116922240 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZM71PjIOF_I",
        "colab": {}
      },
      "source": [
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCYOL8HbIZu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(bert_model_hub)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      bert_model_hub,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "      bert_model_hub = bert_model_hub,\n",
        "      num_labels=len(label_list),\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, \n",
        "               MAX_SEQ_LENGTH = 128,\n",
        "              BATCH_SIZE = 32,\n",
        "              LEARNING_RATE = 2e-5,\n",
        "              NUM_TRAIN_EPOCHS = 3.0,\n",
        "              WARMUP_PROPORTION = 0.1,\n",
        "              SAVE_SUMMARY_STEPS = 100,\n",
        "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
        "              bert_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"):\n",
        "\n",
        "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
        "    \n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "                                  bert_model_hub, \n",
        "                                  OUTPUT_DIR, \n",
        "                                  SAVE_SUMMARY_STEPS, \n",
        "                                  SAVE_CHECKPOINTS_STEPS, \n",
        "                                  label_list, \n",
        "                                  LEARNING_RATE, \n",
        "                                  num_train_steps, \n",
        "                                  num_warmup_steps, \n",
        "                                  BATCH_SIZE)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    return result_dict, estimator\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wpUHTA8LIZu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qmP8MBvjIZvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = 'output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV3ExI2JJMhd",
        "colab_type": "text"
      },
      "source": [
        "----- you just need to focus from here ------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUjVoFtJVEO",
        "colab_type": "text"
      },
      "source": [
        "## Get your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ6CestJXZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "954677bd-ce47-479e-8323-95cc545a6ff9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-29 22:32:30--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12909082 (12M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-29 22:32:31 (103 MB/s) - ‘test.csv’ saved [12909082/12909082]\n",
            "\n",
            "--2019-05-29 22:32:33--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43221547 (41M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  41.22M   148MB/s    in 0.3s    \n",
            "\n",
            "2019-05-29 22:32:34 (148 MB/s) - ‘train.csv’ saved [43221547/43221547]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFBwDlmnIZvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tju0c4dqIZvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9BAxyKhKirc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4cf40a33-0853-4281-b939-5a7403e052c2"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>Hard to believe that director Barbet Schroeder...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23168</th>\n",
              "      <td>This film is a stunning piece that will convin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16843</th>\n",
              "      <td>A series of random, seemingly insignificant th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20368</th>\n",
              "      <td>Ever since seeing this film as a child, over 3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21809</th>\n",
              "      <td>This film has been on my wish list for ten yea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "234    Hard to believe that director Barbet Schroeder...      0\n",
              "23168  This film is a stunning piece that will convin...      1\n",
              "16843  A series of random, seemingly insignificant th...      1\n",
              "20368  Ever since seeing this film as a child, over 3...      1\n",
              "21809  This film has been on my wish list for ten yea...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDh-VkaxIcJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1558bb36-ef5e-46d4-f3eb-32bb5a6c3af3"
      },
      "source": [
        "#train.shape\n",
        "test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUuX8u8Itdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e185861-7909-4ad6-acd2-01f27d4a321b"
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM8M7k0gKk5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myparam = {\n",
        "        \"DATA_COLUMN\": \"review\",\n",
        "        \"LABEL_COLUMN\": \"label\",\n",
        "        \"LEARNING_RATE\": 2e-5,\n",
        "        \"NUM_TRAIN_EPOCHS\":3\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg2apeXpMqG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6446
        },
        "outputId": "f7a61648-9087-4534-c50f-a2c7b757bc77"
      },
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 22:34:34.501497 140576116922240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:36.450766 140576116922240 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.517054 140576116922240 run_classifier.py:774] Writing example 0 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.527976 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.529898 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hard to believe that director bar ##bet sc ##hr ##oed ##er once did the majestic and very funny mai ##tres ##se ( 1976 ) , and now only seems to do \" by the numbers \" hollywood thriller ##s . < br / > < br / > this is very lightweight john gr ##isha ##m material , crossed with the plot of a tv movie . bullock is cass may ##weather , a fei ##sty and independent crime investigator specialising in serial killers . ben chaplin is her reserved police partner sam kennedy , and together they make an uncomfortable duo . not good , when two un ##balance ##d college mala ##dr ##iot ##s ( go ##sling and pitt ) decide to send them [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.531883 140576116922240 run_classifier.py:464] tokens: [CLS] hard to believe that director bar ##bet sc ##hr ##oed ##er once did the majestic and very funny mai ##tres ##se ( 1976 ) , and now only seems to do \" by the numbers \" hollywood thriller ##s . < br / > < br / > this is very lightweight john gr ##isha ##m material , crossed with the plot of a tv movie . bullock is cass may ##weather , a fei ##sty and independent crime investigator specialising in serial killers . ben chaplin is her reserved police partner sam kennedy , and together they make an uncomfortable duo . not good , when two un ##balance ##d college mala ##dr ##iot ##s ( go ##sling and pitt ) decide to send them [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2524 2000 2903 2008 2472 3347 20915 8040 8093 29099 2121 2320 2106 1996 22337 1998 2200 6057 14736 19168 3366 1006 3299 1007 1010 1998 2085 2069 3849 2000 2079 1000 2011 1996 3616 1000 5365 10874 2015 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2003 2200 12038 2198 24665 24032 2213 3430 1010 4625 2007 1996 5436 1997 1037 2694 3185 1012 25200 2003 16220 2089 28949 1010 1037 24664 21756 1998 2981 4126 14064 23315 1999 7642 15978 1012 3841 23331 2003 2014 9235 2610 4256 3520 5817 1010 1998 2362 2027 2191 2019 8796 6829 1012 2025 2204 1010 2043 2048 4895 26657 2094 2267 28935 13626 25185 2015 1006 2175 28886 1998 15091 1007 5630 2000 4604 2068 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.533719 140576116922240 run_classifier.py:465] input_ids: 101 2524 2000 2903 2008 2472 3347 20915 8040 8093 29099 2121 2320 2106 1996 22337 1998 2200 6057 14736 19168 3366 1006 3299 1007 1010 1998 2085 2069 3849 2000 2079 1000 2011 1996 3616 1000 5365 10874 2015 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2003 2200 12038 2198 24665 24032 2213 3430 1010 4625 2007 1996 5436 1997 1037 2694 3185 1012 25200 2003 16220 2089 28949 1010 1037 24664 21756 1998 2981 4126 14064 23315 1999 7642 15978 1012 3841 23331 2003 2014 9235 2610 4256 3520 5817 1010 1998 2362 2027 2191 2019 8796 6829 1012 2025 2204 1010 2043 2048 4895 26657 2094 2267 28935 13626 25185 2015 1006 2175 28886 1998 15091 1007 5630 2000 4604 2068 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.535807 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.537604 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.539385 140576116922240 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.543561 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.545274 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this film is a stunning piece that will convince even the most skeptical viewer that gerard de ##par ##die ##u is one of the finest film actors of the last 50 years . his performance shocks , entertain ##s , disgust ##s and charms you while leaving you breathless . this film was shot in the very early days of his film career and is very raw , but still is able to convey the mastery of de ##par ##die ##u . a must - see for any de ##par ##die ##u fan and by far his best early work . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.547018 140576116922240 run_classifier.py:464] tokens: [CLS] this film is a stunning piece that will convince even the most skeptical viewer that gerard de ##par ##die ##u is one of the finest film actors of the last 50 years . his performance shocks , entertain ##s , disgust ##s and charms you while leaving you breathless . this film was shot in the very early days of his film career and is very raw , but still is able to convey the mastery of de ##par ##die ##u . a must - see for any de ##par ##die ##u fan and by far his best early work . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2143 2003 1037 14726 3538 2008 2097 8054 2130 1996 2087 18386 13972 2008 11063 2139 19362 10265 2226 2003 2028 1997 1996 10418 2143 5889 1997 1996 2197 2753 2086 1012 2010 2836 28215 1010 20432 2015 1010 12721 2015 1998 24044 2017 2096 2975 2017 16701 1012 2023 2143 2001 2915 1999 1996 2200 2220 2420 1997 2010 2143 2476 1998 2003 2200 6315 1010 2021 2145 2003 2583 2000 16636 1996 26364 1997 2139 19362 10265 2226 1012 1037 2442 1011 2156 2005 2151 2139 19362 10265 2226 5470 1998 2011 2521 2010 2190 2220 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.548850 140576116922240 run_classifier.py:465] input_ids: 101 2023 2143 2003 1037 14726 3538 2008 2097 8054 2130 1996 2087 18386 13972 2008 11063 2139 19362 10265 2226 2003 2028 1997 1996 10418 2143 5889 1997 1996 2197 2753 2086 1012 2010 2836 28215 1010 20432 2015 1010 12721 2015 1998 24044 2017 2096 2975 2017 16701 1012 2023 2143 2001 2915 1999 1996 2200 2220 2420 1997 2010 2143 2476 1998 2003 2200 6315 1010 2021 2145 2003 2583 2000 16636 1996 26364 1997 2139 19362 10265 2226 1012 1037 2442 1011 2156 2005 2151 2139 19362 10265 2226 5470 1998 2011 2521 2010 2190 2220 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.550472 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.552400 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.554211 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.566990 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.568955 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a series of random , seemingly insignificant theft ##s at her sister ' s boarding house has miss lemon quite agitated . a ring , light bulbs , a ru ##cks ##ack , a lighter , a ste ##th ##os ##cope , a shoe a ? there seems to be no rhyme or reason to any of it . miss lemon asks her employer , the great belgian detective her ##cule po ##iro ##t , to look into the matter . but what po ##iro ##t sees is something far more sinister than miss lemon could have imagined . and po ##iro ##t ' s fears are confirmed when one of the students living in the boarding house if found murdered . it ' s up [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.570785 140576116922240 run_classifier.py:464] tokens: [CLS] a series of random , seemingly insignificant theft ##s at her sister ' s boarding house has miss lemon quite agitated . a ring , light bulbs , a ru ##cks ##ack , a lighter , a ste ##th ##os ##cope , a shoe a ? there seems to be no rhyme or reason to any of it . miss lemon asks her employer , the great belgian detective her ##cule po ##iro ##t , to look into the matter . but what po ##iro ##t sees is something far more sinister than miss lemon could have imagined . and po ##iro ##t ' s fears are confirmed when one of the students living in the boarding house if found murdered . it ' s up [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 2186 1997 6721 1010 9428 27018 11933 2015 2012 2014 2905 1005 1055 9405 2160 2038 3335 14380 3243 21568 1012 1037 3614 1010 2422 25548 1010 1037 21766 10603 8684 1010 1037 9442 1010 1037 26261 2705 2891 16186 1010 1037 10818 1037 1029 2045 3849 2000 2022 2053 20622 2030 3114 2000 2151 1997 2009 1012 3335 14380 5176 2014 11194 1010 1996 2307 6995 6317 2014 21225 13433 9711 2102 1010 2000 2298 2046 1996 3043 1012 2021 2054 13433 9711 2102 5927 2003 2242 2521 2062 16491 2084 3335 14380 2071 2031 8078 1012 1998 13433 9711 2102 1005 1055 10069 2024 4484 2043 2028 1997 1996 2493 2542 1999 1996 9405 2160 2065 2179 7129 1012 2009 1005 1055 2039 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.572459 140576116922240 run_classifier.py:465] input_ids: 101 1037 2186 1997 6721 1010 9428 27018 11933 2015 2012 2014 2905 1005 1055 9405 2160 2038 3335 14380 3243 21568 1012 1037 3614 1010 2422 25548 1010 1037 21766 10603 8684 1010 1037 9442 1010 1037 26261 2705 2891 16186 1010 1037 10818 1037 1029 2045 3849 2000 2022 2053 20622 2030 3114 2000 2151 1997 2009 1012 3335 14380 5176 2014 11194 1010 1996 2307 6995 6317 2014 21225 13433 9711 2102 1010 2000 2298 2046 1996 3043 1012 2021 2054 13433 9711 2102 5927 2003 2242 2521 2062 16491 2084 3335 14380 2071 2031 8078 1012 1998 13433 9711 2102 1005 1055 10069 2024 4484 2043 2028 1997 1996 2493 2542 1999 1996 9405 2160 2065 2179 7129 1012 2009 1005 1055 2039 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.574210 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.575797 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.577312 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.582582 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.584372 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ever since seeing this film as a child , over 30 years ago , i never tire of watching it . from the opening scenes in the horn factory , to the car motor running from the back seat of the car , to ollie answering the phone and being accidentally pushed out the window by stan , i think this was perhaps their best latter day film . after this they moved to 20th century fox , and while those films weren ' t terrible , they lacked the comic timing of this movie . jimmy finn ##lay ##son , their long time foil , in his last appearance with the boys , showing up as the doctor is super ! quote : \" i [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.585968 140576116922240 run_classifier.py:464] tokens: [CLS] ever since seeing this film as a child , over 30 years ago , i never tire of watching it . from the opening scenes in the horn factory , to the car motor running from the back seat of the car , to ollie answering the phone and being accidentally pushed out the window by stan , i think this was perhaps their best latter day film . after this they moved to 20th century fox , and while those films weren ' t terrible , they lacked the comic timing of this movie . jimmy finn ##lay ##son , their long time foil , in his last appearance with the boys , showing up as the doctor is super ! quote : \" i [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2412 2144 3773 2023 2143 2004 1037 2775 1010 2058 2382 2086 3283 1010 1045 2196 12824 1997 3666 2009 1012 2013 1996 3098 5019 1999 1996 7109 4713 1010 2000 1996 2482 5013 2770 2013 1996 2067 2835 1997 1996 2482 1010 2000 25208 10739 1996 3042 1998 2108 9554 3724 2041 1996 3332 2011 9761 1010 1045 2228 2023 2001 3383 2037 2190 3732 2154 2143 1012 2044 2023 2027 2333 2000 3983 2301 4419 1010 1998 2096 2216 3152 4694 1005 1056 6659 1010 2027 10858 1996 5021 10984 1997 2023 3185 1012 5261 9303 8485 3385 1010 2037 2146 2051 17910 1010 1999 2010 2197 3311 2007 1996 3337 1010 4760 2039 2004 1996 3460 2003 3565 999 14686 1024 1000 1045 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.587520 140576116922240 run_classifier.py:465] input_ids: 101 2412 2144 3773 2023 2143 2004 1037 2775 1010 2058 2382 2086 3283 1010 1045 2196 12824 1997 3666 2009 1012 2013 1996 3098 5019 1999 1996 7109 4713 1010 2000 1996 2482 5013 2770 2013 1996 2067 2835 1997 1996 2482 1010 2000 25208 10739 1996 3042 1998 2108 9554 3724 2041 1996 3332 2011 9761 1010 1045 2228 2023 2001 3383 2037 2190 3732 2154 2143 1012 2044 2023 2027 2333 2000 3983 2301 4419 1010 1998 2096 2216 3152 4694 1005 1056 6659 1010 2027 10858 1996 5021 10984 1997 2023 3185 1012 5261 9303 8485 3385 1010 2037 2146 2051 17910 1010 1999 2010 2197 3311 2007 1996 3337 1010 4760 2039 2004 1996 3460 2003 3565 999 14686 1024 1000 1045 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.589211 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.590807 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.592306 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.601398 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.603144 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this film has been on my wish list for ten years and i only recently found it on dvd when my partner ' s grandson was given it . he watched it at and was thrilled to learn that it was about my generation - born in 1930 and evacuated in 1939 and he wanted to know more about it - and me . luckily i borrowed it from him and watched it on my own and i cried all through it . not only did it capture the emotions , the class distinction , the hardship and the warmth of human relationships of those years ( as well as the cruel ##ties ( spoken and unspoken ) ; but it was accurate ! i am [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.604875 140576116922240 run_classifier.py:464] tokens: [CLS] this film has been on my wish list for ten years and i only recently found it on dvd when my partner ' s grandson was given it . he watched it at and was thrilled to learn that it was about my generation - born in 1930 and evacuated in 1939 and he wanted to know more about it - and me . luckily i borrowed it from him and watched it on my own and i cried all through it . not only did it capture the emotions , the class distinction , the hardship and the warmth of human relationships of those years ( as well as the cruel ##ties ( spoken and unspoken ) ; but it was accurate ! i am [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2143 2038 2042 2006 2026 4299 2862 2005 2702 2086 1998 1045 2069 3728 2179 2009 2006 4966 2043 2026 4256 1005 1055 7631 2001 2445 2009 1012 2002 3427 2009 2012 1998 2001 16082 2000 4553 2008 2009 2001 2055 2026 4245 1011 2141 1999 4479 1998 13377 1999 3912 1998 2002 2359 2000 2113 2062 2055 2009 1011 1998 2033 1012 15798 1045 11780 2009 2013 2032 1998 3427 2009 2006 2026 2219 1998 1045 6639 2035 2083 2009 1012 2025 2069 2106 2009 5425 1996 6699 1010 1996 2465 7835 1010 1996 26479 1998 1996 8251 1997 2529 6550 1997 2216 2086 1006 2004 2092 2004 1996 10311 7368 1006 5287 1998 25982 1007 1025 2021 2009 2001 8321 999 1045 2572 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.606513 140576116922240 run_classifier.py:465] input_ids: 101 2023 2143 2038 2042 2006 2026 4299 2862 2005 2702 2086 1998 1045 2069 3728 2179 2009 2006 4966 2043 2026 4256 1005 1055 7631 2001 2445 2009 1012 2002 3427 2009 2012 1998 2001 16082 2000 4553 2008 2009 2001 2055 2026 4245 1011 2141 1999 4479 1998 13377 1999 3912 1998 2002 2359 2000 2113 2062 2055 2009 1011 1998 2033 1012 15798 1045 11780 2009 2013 2032 1998 3427 2009 2006 2026 2219 1998 1045 6639 2035 2083 2009 1012 2025 2069 2106 2009 5425 1996 6699 1010 1996 2465 7835 1010 1996 26479 1998 1996 8251 1997 2529 6550 1997 2216 2086 1006 2004 2092 2004 1996 10311 7368 1006 5287 1998 25982 1007 1025 2021 2009 2001 8321 999 1045 2572 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.608087 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.609722 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:34:39.611203 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:35:27.425298 140576116922240 run_classifier.py:774] Writing example 10000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:36:14.763928 140576116922240 run_classifier.py:774] Writing example 20000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:04.311957 140576116922240 run_classifier.py:774] Writing example 30000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.210905 140576116922240 run_classifier.py:774] Writing example 0 of 10000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.216435 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.218472 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.222663 140576116922240 run_classifier.py:464] tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.224908 140576116922240 run_classifier.py:465] input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.226900 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.228956 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.230730 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.242774 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.244747 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.246684 140576116922240 run_classifier.py:464] tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.248699 140576116922240 run_classifier.py:465] input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.250936 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.253036 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.255073 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.264962 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.266978 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.268942 140576116922240 run_classifier.py:464] tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.271106 140576116922240 run_classifier.py:465] input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.273284 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.275211 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.277081 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.282233 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.284391 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.286422 140576116922240 run_classifier.py:464] tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.288265 140576116922240 run_classifier.py:465] input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.290174 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.292212 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.293981 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.301743 140576116922240 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.303902 140576116922240 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.305740 140576116922240 run_classifier.py:464] tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.307599 140576116922240 run_classifier.py:465] input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.309499 140576116922240 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.311205 140576116922240 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:37:16.313256 140576116922240 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fda02f295f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:02.694521 140576116922240 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fda02f295f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:19.880732 140576116922240 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:22.937233 140576116922240 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 22:38:23.053728 140576116922240 deprecation.py:506] From <ipython-input-6-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 22:38:23.096602 140576116922240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 22:38:23.470201 140576116922240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 22:38:31.635254 140576116922240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:34.314932 140576116922240 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:34.318916 140576116922240 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:38.399200 140576116922240 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:42.987365 140576116922240 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:38:43.191798 140576116922240 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:39:02.876354 140576116922240 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.8046522, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:39:19.888885 140576116922240 basic_session_run_hooks.py:249] loss = 0.8046522, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.925329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:41:07.957987 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 0.925329\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.38431752, step = 101 (108.072 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:41:07.960573 140576116922240 basic_session_run_hooks.py:247] loss = 0.38431752, step = 101 (108.072 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:42:45.485941 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02535\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.41131788, step = 200 (97.528 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:42:45.488365 140576116922240 basic_session_run_hooks.py:247] loss = 0.41131788, step = 200 (97.528 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:44:22.651592 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02917\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20951968, step = 300 (97.169 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:44:22.656950 140576116922240 basic_session_run_hooks.py:247] loss = 0.20951968, step = 300 (97.169 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:45:59.923745 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02804\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.33058614, step = 400 (97.269 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:45:59.925772 140576116922240 basic_session_run_hooks.py:247] loss = 0.33058614, step = 400 (97.269 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:47:37.267941 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02728\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3551451, step = 500 (97.346 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:47:37.272241 140576116922240 basic_session_run_hooks.py:247] loss = 0.3551451, step = 500 (97.346 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:49:14.365838 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02989\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.26956314, step = 600 (97.098 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:49:14.370386 140576116922240 basic_session_run_hooks.py:247] loss = 0.26956314, step = 600 (97.098 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:50:51.532279 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02916\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.54845893, step = 700 (97.168 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:50:51.537917 140576116922240 basic_session_run_hooks.py:247] loss = 0.54845893, step = 700 (97.168 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:52:28.791835 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02818\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2202657, step = 800 (97.259 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:52:28.796422 140576116922240 basic_session_run_hooks.py:247] loss = 0.2202657, step = 800 (97.259 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:54:06.172966 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02689\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.27305317, step = 900 (97.380 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:54:06.176719 140576116922240 basic_session_run_hooks.py:247] loss = 0.27305317, step = 900 (97.380 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:55:43.498863 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02748\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.1524983, step = 1000 (97.325 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:55:43.501863 140576116922240 basic_session_run_hooks.py:247] loss = 0.1524983, step = 1000 (97.325 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:57:20.775022 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.028\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.12451252, step = 1100 (97.275 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:57:20.777244 140576116922240 basic_session_run_hooks.py:247] loss = 0.12451252, step = 1100 (97.275 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:58:57.917819 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02941\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.1560472, step = 1200 (97.144 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 22:58:57.921643 140576116922240 basic_session_run_hooks.py:247] loss = 0.1560472, step = 1200 (97.144 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:00:35.396183 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02587\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.06147308, step = 1300 (97.477 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:00:35.398370 140576116922240 basic_session_run_hooks.py:247] loss = 0.06147308, step = 1300 (97.477 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:02:12.907316 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02552\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.09269446, step = 1400 (97.514 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:02:12.912769 140576116922240 basic_session_run_hooks.py:247] loss = 0.09269446, step = 1400 (97.514 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:03:50.454893 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02514\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3010163, step = 1500 (97.548 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:03:50.460880 140576116922240 basic_session_run_hooks.py:247] loss = 0.3010163, step = 1500 (97.548 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:05:28.033776 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02481\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.07576715, step = 1600 (97.577 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:05:28.038115 140576116922240 basic_session_run_hooks.py:247] loss = 0.07576715, step = 1600 (97.577 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:07:05.730682 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02357\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08459144, step = 1700 (97.697 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:07:05.735010 140576116922240 basic_session_run_hooks.py:247] loss = 0.08459144, step = 1700 (97.697 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:08:43.255874 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02538\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.04647422, step = 1800 (97.523 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:08:43.258219 140576116922240 basic_session_run_hooks.py:247] loss = 0.04647422, step = 1800 (97.523 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:10:20.553409 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02778\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.1199184, step = 1900 (97.299 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:10:20.557338 140576116922240 basic_session_run_hooks.py:247] loss = 0.1199184, step = 1900 (97.299 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:11:57.739195 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02896\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.05035905, step = 2000 (97.184 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:11:57.741474 140576116922240 basic_session_run_hooks.py:247] loss = 0.05035905, step = 2000 (97.184 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:13:34.866369 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02958\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0068309633, step = 2100 (97.129 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:13:34.870463 140576116922240 basic_session_run_hooks.py:247] loss = 0.0068309633, step = 2100 (97.129 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:15:12.096007 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02849\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0057937927, step = 2200 (97.228 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:15:12.098546 140576116922240 basic_session_run_hooks.py:247] loss = 0.0057937927, step = 2200 (97.228 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:16:49.249190 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.0293\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.07786745, step = 2300 (97.153 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:16:49.251386 140576116922240 basic_session_run_hooks.py:247] loss = 0.07786745, step = 2300 (97.153 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:18:26.517268 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02809\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0030635654, step = 2400 (97.269 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:18:26.520497 140576116922240 basic_session_run_hooks.py:247] loss = 0.0030635654, step = 2400 (97.269 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:20:03.810264 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02782\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.010960127, step = 2500 (97.294 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:20:03.814369 140576116922240 basic_session_run_hooks.py:247] loss = 0.010960127, step = 2500 (97.294 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:21:41.212616 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.004358698, step = 2600 (97.401 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:21:41.215333 140576116922240 basic_session_run_hooks.py:247] loss = 0.004358698, step = 2600 (97.401 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:23:18.774570 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02499\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0038418625, step = 2700 (97.563 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:23:18.778743 140576116922240 basic_session_run_hooks.py:247] loss = 0.0038418625, step = 2700 (97.563 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:24:56.314796 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02522\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.003941219, step = 2800 (97.539 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:24:56.317336 140576116922240 basic_session_run_hooks.py:247] loss = 0.003941219, step = 2800 (97.539 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:26:33.750777 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02632\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0021344943, step = 2900 (97.436 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:26:33.753302 140576116922240 basic_session_run_hooks.py:247] loss = 0.0021344943, step = 2900 (97.436 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.02415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:28:11.392760 140576116922240 basic_session_run_hooks.py:680] global_step/sec: 1.02415\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0030647381, step = 3000 (97.644 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:28:11.397556 140576116922240 basic_session_run_hooks.py:247] loss = 0.0030647381, step = 3000 (97.644 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3046 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:28:55.398592 140576116922240 basic_session_run_hooks.py:594] Saving checkpoints for 3046 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.19497725.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:05.099177 140576116922240 estimator.py:359] Loss for final step: 0.19497725.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:10.307137 140576116922240 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:14.129331 140576116922240 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:23.117424 140576116922240 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-29T23:29:23Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:23.141574 140576116922240 evaluation.py:257] Starting evaluation at 2019-05-29T23:29:23Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:25.033966 140576116922240 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0529 23:29:25.044169 140576116922240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-3046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:25.050248 140576116922240 saver.py:1270] Restoring parameters from output/model.ckpt-3046\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:27.170729 140576116922240 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:29:27.397945 140576116922240 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-29-23:31:05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:31:05.564267 140576116922240 evaluation.py:277] Finished evaluation at 2019-05-29-23:31:05\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 3046: auc = 0.88759995, eval_accuracy = 0.8876, f1_score = 0.8830628, false_negatives = 756.0, false_positives = 368.0, global_step = 3046, loss = 0.48809752, precision = 0.92020816, recall = 0.8488, true_negatives = 4632.0, true_positives = 4244.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:31:05.568227 140576116922240 estimator.py:1979] Saving dict for global step 3046: auc = 0.88759995, eval_accuracy = 0.8876, f1_score = 0.8830628, false_negatives = 756.0, false_positives = 368.0, global_step = 3046, loss = 0.48809752, precision = 0.92020816, recall = 0.8488, true_negatives = 4632.0, true_positives = 4244.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3046: output/model.ckpt-3046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0529 23:31:07.923891 140576116922240 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3046: output/model.ckpt-3046\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOvtveTMqwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "1da3bd85-309c-4c34-f766-654890cb79a5"
      },
      "source": [
        "pretty_print(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>auc</th>\n",
              "      <td>0.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.883063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_negatives</th>\n",
              "      <td>756.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_positives</th>\n",
              "      <td>368.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>global_step</th>\n",
              "      <td>3046.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.488098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.920208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.848800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_negatives</th>\n",
              "      <td>4632.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_positives</th>\n",
              "      <td>4244.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      values\n",
              "auc                 0.887600\n",
              "eval_accuracy       0.887600\n",
              "f1_score            0.883063\n",
              "false_negatives   756.000000\n",
              "false_positives   368.000000\n",
              "global_step      3046.000000\n",
              "loss                0.488098\n",
              "precision           0.920208\n",
              "recall              0.848800\n",
              "true_negatives   4632.000000\n",
              "true_positives   4244.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OPTDcGMsJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}