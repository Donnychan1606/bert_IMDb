{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-text-binary-classification-with-bert-Donny.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donnychan1606/bert_IMDb/blob/master/demo_text_binary_classification_with_bert_Donny_epoch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbAMqZ6IZuw",
        "colab_type": "text"
      },
      "source": [
        "base code borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
        "\n",
        "Refactored by [Shuyi Wang](https://www.linkedin.com/in/shuyi-wang-b3955026/)\n",
        "\n",
        "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "trusted": true,
        "outputId": "a85b6ff4-669e-4ff0-e632-c6d3c1665c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "trusted": true,
        "outputId": "dc0ee15b-3b1b-4d2d-c80e-7d9c27c4147c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0530 14:01:31.264985 140335701657472 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZM71PjIOF_I",
        "colab": {}
      },
      "source": [
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCYOL8HbIZu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(bert_model_hub)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      bert_model_hub,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "      bert_model_hub = bert_model_hub,\n",
        "      num_labels=len(label_list),\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, \n",
        "               MAX_SEQ_LENGTH = 128,\n",
        "              BATCH_SIZE = 32,\n",
        "              LEARNING_RATE = 2e-5,\n",
        "              NUM_TRAIN_EPOCHS = 2.0,\n",
        "              WARMUP_PROPORTION = 0.1,\n",
        "              SAVE_SUMMARY_STEPS = 100,\n",
        "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
        "              bert_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"):\n",
        "\n",
        "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
        "    \n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "                                  bert_model_hub, \n",
        "                                  OUTPUT_DIR, \n",
        "                                  SAVE_SUMMARY_STEPS, \n",
        "                                  SAVE_CHECKPOINTS_STEPS, \n",
        "                                  label_list, \n",
        "                                  LEARNING_RATE, \n",
        "                                  num_train_steps, \n",
        "                                  num_warmup_steps, \n",
        "                                  BATCH_SIZE)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    return result_dict, estimator\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wpUHTA8LIZu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qmP8MBvjIZvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = 'output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV3ExI2JJMhd",
        "colab_type": "text"
      },
      "source": [
        "----- you just need to focus from here ------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUjVoFtJVEO",
        "colab_type": "text"
      },
      "source": [
        "## Get your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ6CestJXZK",
        "colab_type": "code",
        "outputId": "22400991-2070-428f-c1b8-098b2a5fabd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
        "!wget https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-30 14:01:34--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12909082 (12M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "\rtest.csv              0%[                    ]       0  --.-KB/s               \rtest.csv            100%[===================>]  12.31M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-05-30 14:01:34 (142 MB/s) - ‘test.csv’ saved [12909082/12909082]\n",
            "\n",
            "--2019-05-30 14:01:37--  https://raw.githubusercontent.com/Donnychan1606/bert_IMDb/master/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43221547 (41M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  41.22M   238MB/s    in 0.2s    \n",
            "\n",
            "2019-05-30 14:01:38 (238 MB/s) - ‘train.csv’ saved [43221547/43221547]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFBwDlmnIZvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tju0c4dqIZvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8i4a5xUFfe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9BAxyKhKirc",
        "colab_type": "code",
        "outputId": "177a2724-9c8c-4b88-dcdc-9855bad633a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16551</th>\n",
              "      <td>Having seen and loved Greg Lombardo's most rec...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3213</th>\n",
              "      <td>For months preceding the release of this movie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31863</th>\n",
              "      <td>This film reeks of production line planning. I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12829</th>\n",
              "      <td>Well not actually. This movie is very entertai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14054</th>\n",
              "      <td>There are few comedies like this, where almost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "16551  Having seen and loved Greg Lombardo's most rec...      1\n",
              "3213   For months preceding the release of this movie...      0\n",
              "31863  This film reeks of production line planning. I...      0\n",
              "12829  Well not actually. This movie is very entertai...      1\n",
              "14054  There are few comedies like this, where almost...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDh-VkaxIcJq",
        "colab_type": "code",
        "outputId": "04e01d5b-b824-4f81-eb7d-a5b576717142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape\n",
        "#test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUuX8u8Itdc",
        "colab_type": "code",
        "outputId": "3c406b1d-dc01-43b0-8e44-30a8908555ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM8M7k0gKk5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myparam = {\n",
        "        \"DATA_COLUMN\": \"review\",\n",
        "        \"LABEL_COLUMN\": \"label\",\n",
        "        \"LEARNING_RATE\": 2e-5,\n",
        "        \"NUM_TRAIN_EPOCHS\":2\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg2apeXpMqG-",
        "outputId": "bbe49905-c734-4a04-9fd6-a8a46dda120e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5766
        }
      },
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:02:30.912958 140335701657472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:33.100189 140335701657472 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.896021 140335701657472 run_classifier.py:774] Writing example 0 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.904410 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.908870 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] having seen and loved greg lombard ##o ' s most recent film \" knots \" ( he co - wrote and directed that feature as well ) , i decided to check out his earlier work , and this movie was well worth the effort and rental . macbeth in manhattan is a tongue in cheek , excellent take on the shakespeare favorite , updated and moved to nyc . i was impressed by the underlying wit and intelligence of the script and was wow ##ed by the way the storyline of the production in the movie mirrors the storyline of the play itself - and very clever ##ly at that . the trials and tri ##bula ##tions of life in manhattan parallel many a shakespeare [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.912026 140335701657472 run_classifier.py:464] tokens: [CLS] having seen and loved greg lombard ##o ' s most recent film \" knots \" ( he co - wrote and directed that feature as well ) , i decided to check out his earlier work , and this movie was well worth the effort and rental . macbeth in manhattan is a tongue in cheek , excellent take on the shakespeare favorite , updated and moved to nyc . i was impressed by the underlying wit and intelligence of the script and was wow ##ed by the way the storyline of the production in the movie mirrors the storyline of the play itself - and very clever ##ly at that . the trials and tri ##bula ##tions of life in manhattan parallel many a shakespeare [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2383 2464 1998 3866 6754 23441 2080 1005 1055 2087 3522 2143 1000 9439 1000 1006 2002 2522 1011 2626 1998 2856 2008 3444 2004 2092 1007 1010 1045 2787 2000 4638 2041 2010 3041 2147 1010 1998 2023 3185 2001 2092 4276 1996 3947 1998 12635 1012 25182 1999 7128 2003 1037 4416 1999 5048 1010 6581 2202 2006 1996 8101 5440 1010 7172 1998 2333 2000 16392 1012 1045 2001 7622 2011 1996 10318 15966 1998 4454 1997 1996 5896 1998 2001 10166 2098 2011 1996 2126 1996 9994 1997 1996 2537 1999 1996 3185 13536 1996 9994 1997 1996 2377 2993 1011 1998 2200 12266 2135 2012 2008 1012 1996 7012 1998 13012 28507 9285 1997 2166 1999 7128 5903 2116 1037 8101 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.914962 140335701657472 run_classifier.py:465] input_ids: 101 2383 2464 1998 3866 6754 23441 2080 1005 1055 2087 3522 2143 1000 9439 1000 1006 2002 2522 1011 2626 1998 2856 2008 3444 2004 2092 1007 1010 1045 2787 2000 4638 2041 2010 3041 2147 1010 1998 2023 3185 2001 2092 4276 1996 3947 1998 12635 1012 25182 1999 7128 2003 1037 4416 1999 5048 1010 6581 2202 2006 1996 8101 5440 1010 7172 1998 2333 2000 16392 1012 1045 2001 7622 2011 1996 10318 15966 1998 4454 1997 1996 5896 1998 2001 10166 2098 2011 1996 2126 1996 9994 1997 1996 2537 1999 1996 3185 13536 1996 9994 1997 1996 2377 2993 1011 1998 2200 12266 2135 2012 2008 1012 1996 7012 1998 13012 28507 9285 1997 2166 1999 7128 5903 2116 1037 8101 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.917904 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.921063 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.923914 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.938566 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.941145 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] for months preceding the release of this movie you saw it advertised in all sorts of print media , so i patiently waited for its video release to see what all the h ##ype was about . after it was over i had to apologize to my roommate for occupying the vc ##r for the last hour and a half to watch such a horrible movie . it essentially fails because it is a character based movie about un ##red ##eem ##able characters . with the possible exception of amanda pee ##t ( whose only red ##eem ##able quality is that she is amanda pee ##t ) you cannot stand any of them . the film relies on its dialogue which is so ##ph ##omo ##ric [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.943535 140335701657472 run_classifier.py:464] tokens: [CLS] for months preceding the release of this movie you saw it advertised in all sorts of print media , so i patiently waited for its video release to see what all the h ##ype was about . after it was over i had to apologize to my roommate for occupying the vc ##r for the last hour and a half to watch such a horrible movie . it essentially fails because it is a character based movie about un ##red ##eem ##able characters . with the possible exception of amanda pee ##t ( whose only red ##eem ##able quality is that she is amanda pee ##t ) you cannot stand any of them . the film relies on its dialogue which is so ##ph ##omo ##ric [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2005 2706 11003 1996 2713 1997 2023 3185 2017 2387 2009 17099 1999 2035 11901 1997 6140 2865 1010 2061 1045 19080 4741 2005 2049 2678 2713 2000 2156 2054 2035 1996 1044 18863 2001 2055 1012 2044 2009 2001 2058 1045 2018 2000 12134 2000 2026 18328 2005 13992 1996 18315 2099 2005 1996 2197 3178 1998 1037 2431 2000 3422 2107 1037 9202 3185 1012 2009 7687 11896 2138 2009 2003 1037 2839 2241 3185 2055 4895 5596 21564 3085 3494 1012 2007 1996 2825 6453 1997 8282 21392 2102 1006 3005 2069 2417 21564 3085 3737 2003 2008 2016 2003 8282 21392 2102 1007 2017 3685 3233 2151 1997 2068 1012 1996 2143 16803 2006 2049 7982 2029 2003 2061 8458 19506 7277 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.946679 140335701657472 run_classifier.py:465] input_ids: 101 2005 2706 11003 1996 2713 1997 2023 3185 2017 2387 2009 17099 1999 2035 11901 1997 6140 2865 1010 2061 1045 19080 4741 2005 2049 2678 2713 2000 2156 2054 2035 1996 1044 18863 2001 2055 1012 2044 2009 2001 2058 1045 2018 2000 12134 2000 2026 18328 2005 13992 1996 18315 2099 2005 1996 2197 3178 1998 1037 2431 2000 3422 2107 1037 9202 3185 1012 2009 7687 11896 2138 2009 2003 1037 2839 2241 3185 2055 4895 5596 21564 3085 3494 1012 2007 1996 2825 6453 1997 8282 21392 2102 1006 3005 2069 2417 21564 3085 3737 2003 2008 2016 2003 8282 21392 2102 1007 2017 3685 3233 2151 1997 2068 1012 1996 2143 16803 2006 2049 7982 2029 2003 2061 8458 19506 7277 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.949181 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.951610 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.953551 140335701657472 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.961370 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.963173 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this film re ##ek ##s of production line planning . it appears like the filmmakers looked at recent hit movies , and threw spaghetti on the screen - jimmy stewart ! june ally ##son ! anthony mann ! baseball ! war ! baby ! airplane ! - roll ' em ! - the film does address the age of the stewart / ally ##son performers ; though , i ' m certain we are still supposed to think they are much younger . < br / > < br / > there are messages in \" strategic air command \" i found curiously shocking and offensive , but i ' ll stick with one truly wr ##etched element : the happily married couple is challenged when [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.964896 140335701657472 run_classifier.py:464] tokens: [CLS] this film re ##ek ##s of production line planning . it appears like the filmmakers looked at recent hit movies , and threw spaghetti on the screen - jimmy stewart ! june ally ##son ! anthony mann ! baseball ! war ! baby ! airplane ! - roll ' em ! - the film does address the age of the stewart / ally ##son performers ; though , i ' m certain we are still supposed to think they are much younger . < br / > < br / > there are messages in \" strategic air command \" i found curiously shocking and offensive , but i ' ll stick with one truly wr ##etched element : the happily married couple is challenged when [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2143 2128 5937 2015 1997 2537 2240 4041 1012 2009 3544 2066 1996 16587 2246 2012 3522 2718 5691 1010 1998 4711 26666 2006 1996 3898 1011 5261 5954 999 2238 9698 3385 999 4938 10856 999 3598 999 2162 999 3336 999 13297 999 1011 4897 1005 7861 999 1011 1996 2143 2515 4769 1996 2287 1997 1996 5954 1013 9698 3385 9567 1025 2295 1010 1045 1005 1049 3056 2057 2024 2145 4011 2000 2228 2027 2024 2172 3920 1012 1026 7987 1013 1028 1026 7987 1013 1028 2045 2024 7696 1999 1000 6143 2250 3094 1000 1045 2179 16484 16880 1998 5805 1010 2021 1045 1005 2222 6293 2007 2028 5621 23277 29574 5783 1024 1996 11361 2496 3232 2003 8315 2043 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.966602 140335701657472 run_classifier.py:465] input_ids: 101 2023 2143 2128 5937 2015 1997 2537 2240 4041 1012 2009 3544 2066 1996 16587 2246 2012 3522 2718 5691 1010 1998 4711 26666 2006 1996 3898 1011 5261 5954 999 2238 9698 3385 999 4938 10856 999 3598 999 2162 999 3336 999 13297 999 1011 4897 1005 7861 999 1011 1996 2143 2515 4769 1996 2287 1997 1996 5954 1013 9698 3385 9567 1025 2295 1010 1045 1005 1049 3056 2057 2024 2145 4011 2000 2228 2027 2024 2172 3920 1012 1026 7987 1013 1028 1026 7987 1013 1028 2045 2024 7696 1999 1000 6143 2250 3094 1000 1045 2179 16484 16880 1998 5805 1010 2021 1045 1005 2222 6293 2007 2028 5621 23277 29574 5783 1024 1996 11361 2496 3232 2003 8315 2043 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.968226 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.969837 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.971419 140335701657472 run_classifier.py:468] label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.975871 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.977466 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] well not actually . this movie is very entertaining though . went and saw it with the girlfriend last night and had to use the \" i think there might be something in my eye \" routine . the movie is a great combination of comedy and typical romance . jim carey is superb as a down on his luck reporter who is given the power to change himself and the city in which he resides . in fact all the characters are great . the movie is not overly funny or sap ##py , good flick to go see with the wife . < br / > < br / > all in all 8 / 10 . . . . note * i am [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.979217 140335701657472 run_classifier.py:464] tokens: [CLS] well not actually . this movie is very entertaining though . went and saw it with the girlfriend last night and had to use the \" i think there might be something in my eye \" routine . the movie is a great combination of comedy and typical romance . jim carey is superb as a down on his luck reporter who is given the power to change himself and the city in which he resides . in fact all the characters are great . the movie is not overly funny or sap ##py , good flick to go see with the wife . < br / > < br / > all in all 8 / 10 . . . . note * i am [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2092 2025 2941 1012 2023 3185 2003 2200 14036 2295 1012 2253 1998 2387 2009 2007 1996 6513 2197 2305 1998 2018 2000 2224 1996 1000 1045 2228 2045 2453 2022 2242 1999 2026 3239 1000 9410 1012 1996 3185 2003 1037 2307 5257 1997 4038 1998 5171 7472 1012 3958 11782 2003 21688 2004 1037 2091 2006 2010 6735 6398 2040 2003 2445 1996 2373 2000 2689 2370 1998 1996 2103 1999 2029 2002 11665 1012 1999 2755 2035 1996 3494 2024 2307 1012 1996 3185 2003 2025 15241 6057 2030 20066 7685 1010 2204 17312 2000 2175 2156 2007 1996 2564 1012 1026 7987 1013 1028 1026 7987 1013 1028 2035 1999 2035 1022 1013 2184 1012 1012 1012 1012 3602 1008 1045 2572 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.980881 140335701657472 run_classifier.py:465] input_ids: 101 2092 2025 2941 1012 2023 3185 2003 2200 14036 2295 1012 2253 1998 2387 2009 2007 1996 6513 2197 2305 1998 2018 2000 2224 1996 1000 1045 2228 2045 2453 2022 2242 1999 2026 3239 1000 9410 1012 1996 3185 2003 1037 2307 5257 1997 4038 1998 5171 7472 1012 3958 11782 2003 21688 2004 1037 2091 2006 2010 6735 6398 2040 2003 2445 1996 2373 2000 2689 2370 1998 1996 2103 1999 2029 2002 11665 1012 1999 2755 2035 1996 3494 2024 2307 1012 1996 3185 2003 2025 15241 6057 2030 20066 7685 1010 2204 17312 2000 2175 2156 2007 1996 2564 1012 1026 7987 1013 1028 1026 7987 1013 1028 2035 1999 2035 1022 1013 2184 1012 1012 1012 1012 3602 1008 1045 2572 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.982457 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.984143 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.985744 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.993549 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.995228 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] there are few comedies like this , where almost every line and every character come close to flawless . this is soo ##oo funny ! ! and it has quite a bit of satire there to . sally field is heading the field of truly outstanding actors and does a good , if not perfect , job with her daytime tv - diva . sometimes her acting is just a little to broad and over the top , but 90 % of the time she is a riot ! in the same league is kevin k ##line , robert down ##ey jr and who ##op ##y goldberg ( who unfortunately has too little to do here ) . down ##ey jr may not convince entirely as [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.996849 140335701657472 run_classifier.py:464] tokens: [CLS] there are few comedies like this , where almost every line and every character come close to flawless . this is soo ##oo funny ! ! and it has quite a bit of satire there to . sally field is heading the field of truly outstanding actors and does a good , if not perfect , job with her daytime tv - diva . sometimes her acting is just a little to broad and over the top , but 90 % of the time she is a riot ! in the same league is kevin k ##line , robert down ##ey jr and who ##op ##y goldberg ( who unfortunately has too little to do here ) . down ##ey jr may not convince entirely as [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2045 2024 2261 22092 2066 2023 1010 2073 2471 2296 2240 1998 2296 2839 2272 2485 2000 27503 1012 2023 2003 17111 9541 6057 999 999 1998 2009 2038 3243 1037 2978 1997 18312 2045 2000 1012 8836 2492 2003 5825 1996 2492 1997 5621 5151 5889 1998 2515 1037 2204 1010 2065 2025 3819 1010 3105 2007 2014 12217 2694 1011 25992 1012 2823 2014 3772 2003 2074 1037 2210 2000 5041 1998 2058 1996 2327 1010 2021 3938 1003 1997 1996 2051 2016 2003 1037 11421 999 1999 1996 2168 2223 2003 4901 1047 4179 1010 2728 2091 3240 3781 1998 2040 7361 2100 18522 1006 2040 6854 2038 2205 2210 2000 2079 2182 1007 1012 2091 3240 3781 2089 2025 8054 4498 2004 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:36.998413 140335701657472 run_classifier.py:465] input_ids: 101 2045 2024 2261 22092 2066 2023 1010 2073 2471 2296 2240 1998 2296 2839 2272 2485 2000 27503 1012 2023 2003 17111 9541 6057 999 999 1998 2009 2038 3243 1037 2978 1997 18312 2045 2000 1012 8836 2492 2003 5825 1996 2492 1997 5621 5151 5889 1998 2515 1037 2204 1010 2065 2025 3819 1010 3105 2007 2014 12217 2694 1011 25992 1012 2823 2014 3772 2003 2074 1037 2210 2000 5041 1998 2058 1996 2327 1010 2021 3938 1003 1997 1996 2051 2016 2003 1037 11421 999 1999 1996 2168 2223 2003 4901 1047 4179 1010 2728 2091 3240 3781 1998 2040 7361 2100 18522 1006 2040 6854 2038 2205 2210 2000 2079 2182 1007 1012 2091 3240 3781 2089 2025 8054 4498 2004 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:37.000059 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:37.001662 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:02:37.003141 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:03:24.240967 140335701657472 run_classifier.py:774] Writing example 10000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:04:11.064439 140335701657472 run_classifier.py:774] Writing example 20000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 32500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:04:57.285059 140335701657472 run_classifier.py:774] Writing example 30000 of 32500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.056253 140335701657472 run_classifier.py:774] Writing example 0 of 10000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.068120 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.069487 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.070930 140335701657472 run_classifier.py:464] tokens: [CLS] i went and saw this movie last night after being coa ##xed to by a few friends of mine . i ' ll admit that i was reluctant to see it because from what i knew of ashton ku ##tch ##er he was only able to do comedy . i was wrong . ku ##tch ##er played the character of jake fischer very well , and kevin cost ##ner played ben randall with such professional ##ism . the sign of a good movie is that it can toy with our emotions . this one did exactly that . the entire theater ( which was sold out ) was overcome by laughter during the first half of the movie , and were moved to tears during the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.072489 140335701657472 run_classifier.py:465] input_ids: 101 1045 2253 1998 2387 2023 3185 2197 2305 2044 2108 28155 19068 2000 2011 1037 2261 2814 1997 3067 1012 1045 1005 2222 6449 2008 1045 2001 11542 2000 2156 2009 2138 2013 2054 1045 2354 1997 13772 13970 10649 2121 2002 2001 2069 2583 2000 2079 4038 1012 1045 2001 3308 1012 13970 10649 2121 2209 1996 2839 1997 5180 13042 2200 2092 1010 1998 4901 3465 3678 2209 3841 12813 2007 2107 2658 2964 1012 1996 3696 1997 1037 2204 3185 2003 2008 2009 2064 9121 2007 2256 6699 1012 2023 2028 2106 3599 2008 1012 1996 2972 4258 1006 2029 2001 2853 2041 1007 2001 9462 2011 7239 2076 1996 2034 2431 1997 1996 3185 1010 1998 2020 2333 2000 4000 2076 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.074095 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.076634 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.079347 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.097775 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.099450 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.102662 140335701657472 run_classifier.py:464] tokens: [CLS] actor turned director bill paxton follows up his promising debut , the gothic - horror \" frail ##ty \" , with this family friendly sports drama about the 1913 u . s . open where a young american cad ##dy rises from his humble background to play against his br ##ist ##ish idol in what was dubbed as \" the greatest game ever played . \" i ' m no fan of golf , and these scrap ##py under ##dog sports flick ##s are a dime a dozen ( most recently done to grand effect with \" miracle \" and \" cinderella man \" ) , but some how this film was en ##th ##ral ##ling all the same . < br / > < br [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.108494 140335701657472 run_classifier.py:465] input_ids: 101 3364 2357 2472 3021 27765 4076 2039 2010 10015 2834 1010 1996 7788 1011 5469 1000 25737 3723 1000 1010 2007 2023 2155 5379 2998 3689 2055 1996 5124 1057 1012 1055 1012 2330 2073 1037 2402 2137 28353 5149 9466 2013 2010 15716 4281 2000 2377 2114 2010 7987 2923 4509 10282 1999 2054 2001 9188 2004 1000 1996 4602 2208 2412 2209 1012 1000 1045 1005 1049 2053 5470 1997 5439 1010 1998 2122 15121 7685 2104 16168 2998 17312 2015 2024 1037 27211 1037 6474 1006 2087 3728 2589 2000 2882 3466 2007 1000 9727 1000 1998 1000 21686 2158 1000 1007 1010 2021 2070 2129 2023 2143 2001 4372 2705 7941 2989 2035 1996 2168 1012 1026 7987 1013 1028 1026 7987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.113631 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.116084 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.118891 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.128697 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.131318 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.133396 140335701657472 run_classifier.py:464] tokens: [CLS] as a recreational golfer with some knowledge of the sport ' s history , i was pleased with disney ' s sensitivity to the issues of class in golf in the early twentieth century . the movie depicted well the psychological battles that harry var ##don fought within himself , from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society . likewise , the young ou ##ime ##t goes through his own class struggles , being a mere cad ##die in the eyes of the upper crust americans who sc ##off at his attempts to rise above his standing . < br / > < br / [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.135220 140335701657472 run_classifier.py:465] input_ids: 101 2004 1037 10517 20601 2007 2070 3716 1997 1996 4368 1005 1055 2381 1010 1045 2001 7537 2007 6373 1005 1055 14639 2000 1996 3314 1997 2465 1999 5439 1999 1996 2220 9086 2301 1012 1996 3185 8212 2092 1996 8317 7465 2008 4302 13075 5280 4061 2306 2370 1010 2013 2010 5593 12603 1997 2108 25777 2000 2010 2219 13720 2000 3338 2008 3221 5894 2008 16263 2032 2013 2108 3970 2004 2019 5020 1999 2394 5439 2554 1012 10655 1010 1996 2402 15068 14428 2102 3632 2083 2010 2219 2465 11785 1010 2108 1037 8210 28353 10265 1999 1996 2159 1997 1996 3356 19116 4841 2040 8040 7245 2012 2010 4740 2000 4125 2682 2010 3061 1012 1026 7987 1013 1028 1026 7987 1013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.137725 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.139677 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.141510 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.147931 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.149943 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.151807 140335701657472 run_classifier.py:464] tokens: [CLS] i saw this film in a sneak preview , and it is delightful . the cinematography is unusually creative , the acting is good , and the story is fabulous . if this movie does not do well , it won ' t be because it doesn ' t deserve to . before this film , i didn ' t realize how charming shia le ##bo ##uf could be . he does a marvelous , self - contained , job as the lead . there ' s something incredibly sweet about him , and it makes the movie even better . the other actors do a good job as well , and the film contains moments of really high suspense , more than one might expect [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.153589 140335701657472 run_classifier.py:465] input_ids: 101 1045 2387 2023 2143 1999 1037 13583 19236 1010 1998 2009 2003 26380 1012 1996 16434 2003 12890 5541 1010 1996 3772 2003 2204 1010 1998 1996 2466 2003 18783 1012 2065 2023 3185 2515 2025 2079 2092 1010 2009 2180 1005 1056 2022 2138 2009 2987 1005 1056 10107 2000 1012 2077 2023 2143 1010 1045 2134 1005 1056 5382 2129 11951 20474 3393 5092 16093 2071 2022 1012 2002 2515 1037 28851 1010 2969 1011 4838 1010 3105 2004 1996 2599 1012 2045 1005 1055 2242 11757 4086 2055 2032 1010 1998 2009 3084 1996 3185 2130 2488 1012 1996 2060 5889 2079 1037 2204 3105 2004 2092 1010 1998 1996 2143 3397 5312 1997 2428 2152 23873 1010 2062 2084 2028 2453 5987 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.156210 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.158355 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.160190 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.168637 140335701657472 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.171219 140335701657472 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.173026 140335701657472 run_classifier.py:464] tokens: [CLS] bill paxton has taken the true story of the 1913 us golf open and made a film that is about much more than an extra - ordinary game of golf . the film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti - catholic prejudice ##s of both the british and american establishments . but at heart the film is about that perennial favourite of triumph against the odds . < br / > < br / > the acting is exemplary throughout . stephen dil ##lane is excellent as usual , but the revelation of the movie is shia lab ##oe ##uf who delivers a disciplined , dig ##nified and highly sympathetic performance as a working [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.175480 140335701657472 run_classifier.py:465] input_ids: 101 3021 27765 2038 2579 1996 2995 2466 1997 1996 5124 2149 5439 2330 1998 2081 1037 2143 2008 2003 2055 2172 2062 2084 2019 4469 1011 6623 2208 1997 5439 1012 1996 2143 2036 9144 3495 2007 1996 2465 13136 1997 1996 2220 9086 2301 1998 12817 2588 1996 13769 3424 1011 3234 18024 2015 1997 2119 1996 2329 1998 2137 17228 1012 2021 2012 2540 1996 2143 2003 2055 2008 14638 8837 1997 10911 2114 1996 10238 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 3772 2003 27792 2802 1012 4459 29454 20644 2003 6581 2004 5156 1010 2021 1996 11449 1997 1996 3185 2003 20474 6845 8913 16093 2040 18058 1037 28675 1010 10667 25201 1998 3811 13026 2836 2004 1037 2551 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.177601 140335701657472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.179524 140335701657472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:10.181666 140335701657472 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa209583c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:05:54.299026 140335701657472 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa209583c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:10.628708 140335701657472 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:13.946200 140335701657472 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:06:14.079023 140335701657472 deprecation.py:506] From <ipython-input-4-84c7ede190b1>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:06:14.129335 140335701657472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:06:14.526615 140335701657472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:06:23.391366 140335701657472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:26.201780 140335701657472 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:26.205113 140335701657472 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:30.198714 140335701657472 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:34.985375 140335701657472 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:35.194143 140335701657472 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:06:53.597259 140335701657472 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7171446, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:07:10.256110 140335701657472 basic_session_run_hooks.py:249] loss = 0.7171446, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.00064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:08:50.191383 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.00064\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.4658364, step = 100 (99.939 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:08:50.194988 140335701657472 basic_session_run_hooks.py:247] loss = 0.4658364, step = 100 (99.939 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:10:21.631034 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09362\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.18677437, step = 200 (91.441 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:10:21.635991 140335701657472 basic_session_run_hooks.py:247] loss = 0.18677437, step = 200 (91.441 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:11:53.050638 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09386\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.19034469, step = 300 (91.419 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:11:53.054870 140335701657472 basic_session_run_hooks.py:247] loss = 0.19034469, step = 300 (91.419 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:13:24.375222 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.095\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.41451436, step = 400 (91.326 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:13:24.381213 140335701657472 basic_session_run_hooks.py:247] loss = 0.41451436, step = 400 (91.326 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:14:56.067711 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.0906\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.32789698, step = 500 (91.690 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:14:56.071433 140335701657472 basic_session_run_hooks.py:247] loss = 0.32789698, step = 500 (91.690 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:16:27.482716 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09391\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.32983115, step = 600 (91.415 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:16:27.486694 140335701657472 basic_session_run_hooks.py:247] loss = 0.32983115, step = 600 (91.415 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:17:58.825351 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09478\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.35269326, step = 700 (91.341 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:17:58.828134 140335701657472 basic_session_run_hooks.py:247] loss = 0.35269326, step = 700 (91.341 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:19:30.474788 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09111\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.32832256, step = 800 (91.652 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:19:30.479717 140335701657472 basic_session_run_hooks.py:247] loss = 0.32832256, step = 800 (91.652 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:21:02.191914 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09031\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.23134828, step = 900 (91.715 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:21:02.194236 140335701657472 basic_session_run_hooks.py:247] loss = 0.23134828, step = 900 (91.715 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:22:33.684152 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09299\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48264128, step = 1000 (91.494 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:22:33.687953 140335701657472 basic_session_run_hooks.py:247] loss = 0.48264128, step = 1000 (91.494 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:24:04.995649 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09515\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.060359664, step = 1100 (91.313 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:24:05.001179 140335701657472 basic_session_run_hooks.py:247] loss = 0.060359664, step = 1100 (91.313 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:25:36.548306 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09227\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.28637058, step = 1200 (91.552 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:25:36.552983 140335701657472 basic_session_run_hooks.py:247] loss = 0.28637058, step = 1200 (91.552 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:27:08.108603 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09218\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.098128125, step = 1300 (91.558 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:27:08.110666 140335701657472 basic_session_run_hooks.py:247] loss = 0.098128125, step = 1300 (91.558 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:28:39.478546 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09445\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.06996128, step = 1400 (91.375 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:28:39.485840 140335701657472 basic_session_run_hooks.py:247] loss = 0.06996128, step = 1400 (91.375 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:30:10.811128 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.0949\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.013959724, step = 1500 (91.329 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:30:10.815037 140335701657472 basic_session_run_hooks.py:247] loss = 0.013959724, step = 1500 (91.329 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:31:42.198932 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09424\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3530199, step = 1600 (91.388 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:31:42.203222 140335701657472 basic_session_run_hooks.py:247] loss = 0.3530199, step = 1600 (91.388 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:33:13.702657 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0054936674, step = 1700 (91.502 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:33:13.704781 140335701657472 basic_session_run_hooks.py:247] loss = 0.0054936674, step = 1700 (91.502 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.08808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:34:45.607281 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.08808\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.11248942, step = 1800 (91.909 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:34:45.614166 140335701657472 basic_session_run_hooks.py:247] loss = 0.11248942, step = 1800 (91.909 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:36:17.199197 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.0918\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08912674, step = 1900 (91.588 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:36:17.202260 140335701657472 basic_session_run_hooks.py:247] loss = 0.08912674, step = 1900 (91.588 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.09028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:37:48.918557 140335701657472 basic_session_run_hooks.py:680] global_step/sec: 1.09028\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.09613534, step = 2001 (91.724 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:37:48.925766 140335701657472 basic_session_run_hooks.py:247] loss = 0.09613534, step = 2001 (91.724 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2031 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:16.432820 140335701657472 basic_session_run_hooks.py:594] Saving checkpoints for 2031 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.032010518.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:28.000664 140335701657472 estimator.py:359] Loss for final step: 0.032010518.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:36.170206 140335701657472 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:42.244497 140335701657472 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:55.818487 140335701657472 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-30T14:38:55Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:55.852538 140335701657472 evaluation.py:257] Starting evaluation at 2019-05-30T14:38:55Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:58.398541 140335701657472 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 14:38:58.416399 140335701657472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from output/model.ckpt-2031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:38:58.428486 140335701657472 saver.py:1270] Restoring parameters from output/model.ckpt-2031\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:39:01.476681 140335701657472 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:39:01.824805 140335701657472 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-30-14:40:38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:40:38.082276 140335701657472 evaluation.py:277] Finished evaluation at 2019-05-30-14:40:38\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2031: auc = 0.89030004, eval_accuracy = 0.8903, f1_score = 0.8944075, false_negatives = 354.0, false_positives = 743.0, global_step = 2031, loss = 0.35148922, precision = 0.8621265, recall = 0.9292, true_negatives = 4257.0, true_positives = 4646.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:40:38.084354 140335701657472 estimator.py:1979] Saving dict for global step 2031: auc = 0.89030004, eval_accuracy = 0.8903, f1_score = 0.8944075, false_negatives = 354.0, false_positives = 743.0, global_step = 2031, loss = 0.35148922, precision = 0.8621265, recall = 0.9292, true_negatives = 4257.0, true_positives = 4646.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2031: output/model.ckpt-2031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 14:40:40.444635 140335701657472 estimator.py:2039] Saving 'checkpoint_path' summary for global step 2031: output/model.ckpt-2031\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOvtveTMqwp",
        "colab_type": "code",
        "outputId": "6dcf42ce-4177-4d2d-cb49-d470c8f26264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# This is the result with learning rate of 2e-5\n",
        "pretty_print(result)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>auc</th>\n",
              "      <td>0.890300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.890300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.894408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_negatives</th>\n",
              "      <td>354.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>false_positives</th>\n",
              "      <td>743.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>global_step</th>\n",
              "      <td>2031.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>0.351489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.862127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.929200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_negatives</th>\n",
              "      <td>4257.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_positives</th>\n",
              "      <td>4646.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      values\n",
              "auc                 0.890300\n",
              "eval_accuracy       0.890300\n",
              "f1_score            0.894408\n",
              "false_negatives   354.000000\n",
              "false_positives   743.000000\n",
              "global_step      2031.000000\n",
              "loss                0.351489\n",
              "precision           0.862127\n",
              "recall              0.929200\n",
              "true_negatives   4257.000000\n",
              "true_positives   4646.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OPTDcGMsJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the result with learning rate of 1e-4\n",
        "pretty_print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}